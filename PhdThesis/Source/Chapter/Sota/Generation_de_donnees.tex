\section{Génération de données}
\label{section:sota:data_generation}

Dans Praspel, nous exprimons beaucoup plus que les types usuels mais nous
n'exprimons pas des contraintes sous forme logique. Nous sommes alors intéressés
par la génération (et la validation) de données au sens large. Cette partie
présente tout d'abord des techniques de génération de données puis,
orthogonalement, des outils qui génèrent des types de données spécifiques.

\subsection{Technique de génération}

Beaucoup de travaux et d'outils considèrent la génération de données aléatoires
comme efficace pour trouver des erreurs. Elle permet de très rapidement explorer
un modèle, une spécification ou une structure de code à moindre coût. Le
\inenglish{fuzzing}~\acite{GodefroidLM12}, par exemple, est une technique
s'appuyant entre autre sur ces deux aspects~: beaucoup de données différentes
générées rapidement, qui permettent d'éprouver le programme. Malgré ses
limitations évidentes (un test d'égalité entre deux entiers générés
aléatoirement a une probabilité très faible d'être validé), la génération
aléatoire est souvent un moyen de «~déblayer le terrain~» et de repérer les
points non triviaux à tester du programme. C'est pourquoi plusieurs outils
considèrent une approche hybride~: utiliser de l'aléatoire pour éliminer les cas
triviaux et éviter l'utilisation systématique de techniques de génération plus
gourmandes. D'autres techniques vont guider l'aléatoire afin de conserver un
certain degré de non-déterminisme tout en respectant par exemple des critères de
couverture.

D'autres techniques travaillent à partir de solveurs de contraintes. Ces
techniques explorent et analysent le code de manière symbolique et concrète afin
de récolter un ensemble de contraintes. Ce dernier sera résolu afin de générer
des données de test qui seront alors utilisées pour exécuter le programme. Le
terme \inenglish{concolic} est la contraction de \inenglish{concrete} et
\inenglish{symbolic} et désigne ce genre de technique.

Nous présentons quelques outils qui adoptent ces techniques.

\paragraph{EXE} \inenglish{EXecution generated Executions}, abrégé
EXE~\acite{CadarGPDE06, CadarGPDE08}, est un outil d'exécution symbolique pour
programmes C. Au lieu d'exécuter le programme avec des valeurs construites
manuellement ou aléatoirement, EXE va exécuter le programme, préalablement
instrumenté, de manière symbolique. Durant cette exécution symbolique, EXE va
analyser et indexer toutes les contraintes sur les entrées symboliques (comme
les paramètres des fonctions) et ainsi calculer tous les chemins possibles dans
le programme.  Si EXE rencontre une instruction contenant une valeur symbolique,
alors il va analyser son environnement et générer de nouvelles contraintes.
Quand des embranchements sont rencontrés (comme une condition par exemple), EXE
va dupliquer les exécutions et les contraindre à emprunter chaque chemin de
l'embranchement (pour une condition, ce sera un chemin à vrai et un à faux).
Quand EXE arrive à la fin d'un chemin ou qu'il détecte une erreur, alors il va
automatiquement générer des données de test à partir des contraintes récoltées.
EXE est accompagné de STP~\acite{GaneshD07}, un solveur de contraintes dédié
conçu à l'origine pour EXE. C'est grâce à ce solveur que les valeurs vont être
concrétisées et utilisées comme données de test sur le programme
non-instrumenté. Les mêmes chemins seront empruntés et les mêmes erreurs seront
trouvées, mais avec des valeurs concrètes, donc exploitables par le développeur.

\paragraph{KLEE} L'outil KLEE~\acite{CadarDE08} est la suite d'EXE. Ses auteurs
font le constat suivant~: malgré le fait que les travaux sur l'exécution
symbolique soient encourageants, les outils ne sont toujours pas capables de
passer à l'échelle. En effet, le nombre de chemins dans les programmes est
exponentiel, et les techniques d'exécution symbolique n'arrivent plus à résoudre
toutes les contraintes générées. De même, l'exécution symbolique ne prenait pas
en compte l'environnement du programme, comme l'OS, le réseau ou l'utilisateur.
Ce sont ces deux problèmes qu'adresse KLEE grâce à de la réduction et
simplification de contraintes, des améliorations sur l'exploration des chemins
et des optimisations de la représentation de l'environnement. KLEE utilise
toujours STP comme solveur de contraintes.

\paragraph{DART} \inenglish{Directed Automated Random Testing}, abrégé
DART~\acite{GodefroidKS05}, est également un outil de génération de données de
test à partir de l'analyse du programme. DART opère en trois étapes. Il commence
par extraire les interfaces du programme pour connaître ses entrées. Ensuite il
génère aléatoirement des données pour ses entrées, et exécute le programme.
Enfin, il analyse le comportement du programme pendant son exécution pour
détecter quels sont les chemins ou zones qui n'ont pas été atteints. Cette
analyse va permettre de guider la génération des nouvelles entrées pour la
prochaine exécution.

DART et EXE ont une approche similaire pour l'analyse des chemins. À chaque
embranchement du programme, DART va extraire des contraintes symboliques. Pour
générer les données de test suivantes, il prendra la négation des contraintes
une par une, générera de nouvelles valeurs et le processus continuera.
Toutefois, DART ne sait gérer que les contraintes sur les entiers alors qu'EXE
sait gérer des contraintes sur les entiers, les tableaux, les vecteurs de bits,
le transtypage, les opérations arithmétiques etc.

\paragraph{PathCrawler} L'outil PathCrawler~\acite{BotellaDHKMRW09} est un
générateur de tests structurels pour des programmes écrits en C, combinant, lui
aussi, des exécutions symboliques et concrètes. Le test structurel vise à
satisfaire certains critères de couverture de code. PathCrawler utilise son
propre solveur de contraintes, appelé Colibri. Ce dernier est utilisé par
d'autres outils de test et implémente des fonctionnalités avancées comme le
support des réels ou de l'arithmétiques modulaire sur les entiers. PathCrawler
propose plusieurs stratégies de couverture de code, comme
\inenglish{all-$k$-paths} (tous les chemins atteignables avec au plus $k$
itérations dans les boucles) et \inenglish{all-paths} (tous les chemins
atteignables sans limitation d'itérations dans les boucles). PathCrawler est
sûre, c'est~à~dire que chaque cas de test active un objectif de test (un chemin,
une branche, une instruction etc.) pour lequel il a été généré. Cette propriété
est validé par une exécution concrète. Quand toutes les fonctionnalités du
programme testé sont supportées par PathCrawler et quand la génération de test,
impliquant le solveur de contrainte, termine pour tous les chemins, l'outil est
aussi complet, c'est~à~dire que l'absence de cas de test pour certains objectifs
de test signifie que ces objectifs sont inatteignables. Cette propriété est
possible car PathCrawler ne fait pas d'approximation pour les constraintes sur
les chemins, comme c'est le cas dans d'autres outils de type
\inenglish{concolic}. PathCrawler a toutefois des limitations. Par exemple, il
ne supporte pas les structures récursives, les fonctions récursives et les
pointeurs sur les fonctions. \\

Nous pouvons citer CUTE~\acite{SenMA05}, Pex~\acite{TillmannH08},
SAGE~\acite{GodefroidLM12} ou ARTOO~\acite{CiupaLOM08} qui sont aussi des
travaux du même genre. Nous voyons qu'il existe plusieurs techniques avancées
pour la génération de données de test à partir d'exécution symbolique.
Toutefois, si nous repensons aux contrats et que nous prenons du recul, nous
remarquons que l'exécution symbolique ne permet pas de vérifier qu'un programme
fait bien ce que nous souhaitons. Les erreurs à l'exécution (comme des pointeurs
nuls, des dépassements de tableaux, de tampons etc.) seront détectées, mais rien
ne nous assure que le programme est correct par rapport à une spécification.

\subsection{Données générées}

Cette partie s'intéresse à des travaux sur la génération de données (parfois
hors contexte, c'est~à~dire sans considérer un programme). Nos contributions se
situent dans PHP, un langage essentiellement utilisé pour des programmes Web,
c'est~à~dire manipulant majoritairement deux types de données~: des chaînes de
caractères et des collections (aussi appelées tableaux). Cette partie est
découpée en fonction de ces deux types de données.

\paragraph{Génération de chaînes de caractères} Les chaînes de caractères sont
intensivement utilisées dans les programmes Web. Leurs formes sont très
différentes, allant d'une adresse email à des langages comme XML ou JSON, en
passant par des requêtes SQL etc. La façon la plus répandue dans l'industrie
pour représenter une donnée textuelle est d'utiliser une expression régulière ou
une grammaire algébrique~\acite{Chomsky56}. Une grammaire est exprimée à partir
d'un {\strong langage de description} qui déclare des {\strong lexèmes}, unités
lexicales atomiques d'un langage, et des {\strong entités syntaxiques} (aussi
appelées {\strong règles}) exprimant l'enchaînement possible des lexèmes les uns
par rapport aux autres.

L'idée commune que nous retrouvons dans la majorité des travaux est d'explorer
ces règles afin de générer une {\strong séquence de lexèmes} qui représente une
donnée valide. Quand les grammaires sont utilisées pour représenter des données
de test, nous parlons de \inenglish{Grammar-based Testing}, abrégé GbT.

\inenglish{yet another generator-generator}, abrégé yagg~\acite{CoppitL05} est
un outil de génération de données textuelles complexes à partir d'une grammaire
décrite avec une syntaxe très similaire à LEX~\acite{Lesk75} et
YACC~\acite{Johnson75}, des outils d'analyse syntaxique et lexicale très
largement utilisés. Ce choix de syntaxe est montré comme plus attractif et plus
efficace pour les utilisateurs comparé à TestEra à besoin équivalent. Quand est
traité le problème de génération de données structurelles complexes, notamment
avec des grammaires, la question de la combinatoire se pose forcément. Certains
opérateurs de répétition de séquences de lexèmes, comme \code{+} (une ou
plusieurs fois) ou \code{*} (zéro ou plusieurs fois) n'ont pas de bornes
supérieures. Afin d'éviter la génération d'énormes données ou de données
explosives, yagg propose de borner ces opérateurs. yagg a une approche
exhaustive, c'est~à~dire qu'il va énumérer toutes les séquences possibles de
lexèmes. Les lexèmes sont exprimés avec un sous-langage des expressions
régulières qui ajoute des constructions comme l'alternance équivalente ou des
générateurs d'équivalence.  Ce choix sert également à borner les valeurs
possibles des lexèmes.

L'outil Geno~\acite{LammelS06} propose une solution au problème de l'explosion
combinatoire. Certains travaux proposent des critères de couverture sur les
grammaires. D'autres proposent d'annoter des grammaires avec par exemple des
poids probabilistes afin de guider l'exploration de la grammaire. Geno propose à
l'utilisateur d'annoter une grammaire avec des mots-clés afin de guider la
génération. Ces mots-clés sont une abstraction de choix probabilistes, {\em a
priori} plus simples et concrets. Ces mots-clés sont traités de façon à
conserver une certaine exhaustivité dans les résultats. Similairement, l'outil
YouGen~\acite{HoffmanLSW11} propose à l'utilisateur d'ajouter des
\inenglish{tags} pour borner l'exploration de plusieurs règles en appliquant des
réductions \inenglish{pair-wises}.

La plupart des techniques ayant une approche aléatoire ou exhaustive bornée se
basent respectivement sur les travaux de \acitei{Howden86} et
\acitei{FlajoletZC94}. La démarche est très souvent similaire~: à partir d'une
grammaire, il est possible de générer une donnée. Mais des annotations sont
ajoutées pour guider cette génération afin d'obtenir des données plus réalistes
selon le contexte d'utilisation. Ces outils demandent toujours une intervention
du développeur mais ces interventions tendent à devenir de plus en plus simples.

\paragraph{Génération de tableaux} Les tableaux sont aussi très utilisés dans le
Web pour représenter toutes sortes de collections ou organiser de manière
structurelles des informations. Dans la même lignée que TestEra, CUTE ou encore
PathCrawler~\acite{WilliamsMMR05}, nous trouvons Euclide~\acite{Gotlieb09} qui
est un outil de test à partir de contraintes exprimées en ACSL. Euclide mélange
trois aspects~: analyse structurelle du code source du programme, production de
contre-exemples et preuve partielle du programme. L'objectif est de mélanger les
techniques pour dépasser la limite de chacune et ainsi, de générer des données
permettant de satisfaire plus de critères de couverture de code.

{\scshape fdcc}~\acite{BardinG12} est un solveur pour les tableaux avec
contraintes sur des domaines finis. Les auteurs font le constat que les tableaux
sont omniprésents dans les outils de vérification, mais que des approches
efficaces pour les traiter sont assez rares dans la programmation par
contraintes. Les auteurs proposent alors une approche combinant deux solveurs,
l'un raisonnant de manière symbolique (pour connaître les accès, les écritures
et la taille des tableaux), l'autre manipulant des contraintes sur les domaines
finis. La partie originale et difficile est la communication bi-directionnelle
entre ces deux outils.

Mentionnons aussi l'outil Minion~\acite{GentJM06} qui fait un constat et une
approche similaire à {\scshape fdcc}~: les auteurs préfèrent coupler des
solutions ensemble et les faire communiquer. Les résultats sont très
encourageants~: comme pour {\scshape fdcc}, le solveur converge beaucoup plus
rapidement et est capable de répondre à davantage de problèmes. La partie
délicate est toujours de filtrer et transformer les problèmes pour que les
différents solveurs puissent commniquer entre eux.
