\section{Génération à partir de grammaire pour les chaînes de caractères}
\label{section:data:strings}

Une grammaire est utilisée pour représenter des données textuelles complexes.  À
l'aide d'un compilateur, nous allons nous assurer qu'une donnée (textuelle) est
conforme à une grammaire. C'est une propriété sur deux d'un domaine réaliste~:
ce qui fait des grammaires de bonnes candidates pour être une base d'un domaine
réaliste.

Nous allons en premier lieu nous concentrer sur la première caractéristique des
domaines réalistes, à savoir la prédicabilité, et présenter un langage simple de
description de grammaire ainsi que son interprétation avec un compilateur de
compilateur dédié. Ensuite, nous allons voir comment exploiter une grammaire
pour générer des données valides, et ainsi assurer la seconde caractéristique
des domaines réalistes, à savoir la générabilité.

\subsection{Langage de description de grammaire}
\label{subsection:data:pp}

Une grammaire est constituée de {\strong lexèmes}, unités atomiques lexicales
d'une langue, et de {\strong règles} exprimant l'enchaînement possible des
lexèmes les uns par rapport aux autres. Le langage \inenglish{PHP Parser},
abrégé PP, est utilisé pour exprimer des grammaires \inenglish{top-down} et
algébriques. La syntaxe est principalement inspirée de YACC~\acite{Johnson75} et
JavaCC avec l'ajout de nouvelles constructions.

La déclaration d'un lexème est de la forme suivante~:

\begin{pre}
%token ns_source:name value -> ns_dest
\end{pre}
%
où \code{name} représente son nom, \code{value} sa valeur exprimée avec une
expression régulière, et \code{ns\_source} et \code{ns\_dest} sont des espaces
de nom optionnels. Les expressions régulières sont écrites en utilisant la
syntaxe standard des PCRE~\acite{Hazel05}, très expressives, largement utilisées
et supportées (par exemple dans PHP, Javascript, Perl, Python, Apache, KDE
etc.). Les espaces de noms servent à représenter des sous-ensembles disjoints de
lexèmes pour la phase d'analyse lexicale (détaillée ci-après). Une déclaration
\code{\%skip} est similaire à une déclaration \code{\%token} excepté qu'elle
représente un lexème à «~sauter~», c'est~à~dire à ne pas retenir pour la suite.
Typiquement les espaces dans une expression arithmétique n'ont pas d'importance,
nous pouvons les sauter.

Si un espace de nom source n'est pas précisé, alors il prendra la valeur
\code{default}, qui est l'espace de nom par défaut. L'espace de nom de
destination peut être de la forme spéciale \code{\_\_shift\_\_ * $j$}, avec $j
\geq 1$, ou simplement \code{\_\_shift\_\_} (équivalent à avoir $j = 1$), pour
revenir $j$ espaces de nom en arrière. En effet, il est parfois possible
d'accéder à un lexème depuis plusieurs espaces de nom différents. Cette forme
spéciale répond à cette problématique. \\

\begin{figure}

\begin{bigpre}
%skip          space    \(\bslash\)s \\
%token         lt       <            -> in_tag \\
%token         text     [^<]* \\
%skip   in_tag:space    \(\bslash\)s \\
%token  in_tag:name     \(\bslash\)w+ \\
%token  in_tag:slash    / \\
%token  in_tag:gt       >            -> default \\
%token  in_tag:equal    = \\
%token  in_tag:value    ".*?(?<!\(\bslash\bslash\))" \\
\\
xml: \\
    tag()+ #root \\
tag: \\
    ::lt:: <name[0]> attributes() \\
    ( \\
      ::slash:: ::gt:: #atomic \\
    | ::gt:: ( tag()+ #composite | <text> #textual )? \\
      ::lt:: ::slash:: ::name[0]:: ::gt:: \\
    ) \\
#attributes: \\
    ( <name> ::equal:: <value> )*
\end{bigpre}

\caption{\label{figure:data:xml} Grammaire simplifiée d'un document XML.}

\end{figure}

La Figure~\ref{figure:data:xml} montre un exemple d'une grammaire simplifiée
d'un document XML~\acite{xml}. Elle commence par la déclaration des lexèmes, en
utilisant des espaces de noms pour identifier si l'analyse se déroule à
l'extérieur ou à l'intérieur d'une balise. La règle \code{xml} décrit un
document XML comme une séquence de balises, chaque balise ayant potentiellement
des attributs et étant atomique (\code{<aTag />}), composite (contenant d'autres
balises), contenant du texte (\code{<aTag>with text</aTag>}) ou étant vide. Un
nom de règle (\code{xml}, \code{tag} ou \code{attribute} dans la
Figure~\ref{figure:data:xml}) est suivi du symbole \code{:}, puis d'une nouvelle
ligne, immédiatement suivie par une {\strong déclaration de règle}, préfixée par
des caractères blancs horizontaux (espaces ou tabulations). Les lexèmes peuvent
être référencés en utilisant deux types de constructions. La construction
\code{::token::} signifie que le lexème ne sera pas conservé à la fin du
processus de compilation (détaillé ci-après), contrairement à la construction
\code{<token>}. La construction \code{rule()} représente un appel à une règle.
Évidemment, nous pouvons avoir des appels récursifs. Les opérations de
répétition sont classiques: \code{\{$x$, $y$\}} pour répéter le motif $x$ à $y$
fois, \code{?} est identique à \code{\{0, 1\}}, \code{+} à \code{\{1, \}},
\code{*} à \code{\{0, \}}. Les disjonctions sont représentées par le symbole
\code{\mvert} et le groupement par \code{(} et \code{)}. La construction
\code{\#node} (parfois utilisé comme nom de règle) est utile pour la fin du
processus de compilation.

Si un lexème est suivi de \code{[$i$]} avec $i \geq 0$, nous avons une
unification. C'est une nouvelle construction. Une unification pour les lexèmes
implique que tous les \code{token[$i$]} avec le même $i$ ont la même valeur
localement à la règle.  Remarquons la présence d'une unification de lexème dans
la Figure~\ref{figure:data:xml}~: \code{name[0]} indique que les balises
d'ouverture et de fermeture doivent avoir le même nom. Ainsi, la donnée
\code{<foo>…</foo>} sera considérée comme valide, alors que \code{<foo>…</bar>}
sera considérée comme invalide. Un autre usage courant est la gestion des
guillemets représenté par le lexème \code{\%token quote '|"}, soit un guillemet simple, soit
un double. Ainsi, \code{"…"} comme \code{'…'} doivent être valides, alors que
\code{"…'} ou \code{'…"} devront être invalides. Pour cela, nous écrirons par
exemple \code{quote[1]} dans une règle.

Nous trouverons la grammaire du langage PP en langage PP dans la
Figure~\ref{figure:appendices:grammar_of_pp} à la
page~\pageref{figure:appendices:grammar_of_pp}.

\subsection{Compilateur de compilateur $LL(\star)$}
\label{subsection:data:compiler-compiler}

Le fonctionnement schématique d'un compilateur est présenté dans la
Figure~\ref{figure:data:compiler}. À partir d'un {\strong mot} (d'une donnée
textuelle), nous allons extraire une {\strong séquence} de lexèmes grâce à
l'analyseur {\strong lexical}. Ensuite, cette séquence sera {\strong dérivée}
grâce à l'analyseur {\strong syntaxique} pour savoir si elle est valide ou non.
%
\begin{figure}

\fig{\textwidth}{!}{Compiler.tex}

\caption{\label{figure:data:compiler} Fonctionnement d'un compilateur~: un mot
est transformé en séquence de lexèmes grâce à une analyse lexicale. Et cette
séquence est validée ou invalidée grâce à une analyse syntaxique.}

\end{figure}

Nous expliquons le fonctionnement de l'analyseur lexical. Il va appliquer, dans
l'ordre de déclaration, tous les lexèmes de l'espace de nom courant sur le début
du mot jusqu'à trouver un lexème valide (reconnaissant le début du mot). Le
début du mot reconnu est supprimé pour être ajouté à la suite de la séquence,
avec des données supplémentaires (espace de nom, numéro de lignes, de colonnes
etc.). L'espace de nom est actualisé et l'analyseur recommence jusqu'à atteindre
la fin du mot. Si aucun lexème ne permet de reconnaître le début du mot, alors
une erreur sera levée.

\begin{example}[Analyse lexicale de \code{<a x="y"><b /><c>foo</c></a>}]
\label{example:data:lexical_analyze}

Avec la grammaire de la Figure~\ref{figure:data:xml}, l'analyse lexicale de la
donnée~:
%
$$\code{<a x="y"><b /><c>foo</c></a>}$$
%
produit la séquence suivante~:
\begin{center}
\begin{tabular}{rlllr}
   & espace de nom  & lexème       & valeur     & position \\
0  & \code{default} & \code{lt}    & \code{<}   & 0 \\
1  & \code{in\_tag} & \code{name}  & \code{a}   & 1 \\
2  & \code{in\_tag} & \code{name}  & \code{x}   & 3 \\
3  & \code{in\_tag} & \code{equal} & \code{=}   & 4 \\
4  & \code{in\_tag} & \code{value} & \code{"y"} & 5 \\
5  & \code{in\_tag} & \code{gt}    & \code{>}   & 8 \\
6  & \code{default} & \code{lt}    & \code{<}   & 9 \\
7  & \code{in\_tag} & \code{name}  & \code{b}   & 10 \\
8  & \code{in\_tag} & \code{slash} & \code{/}   & 12 \\
9  & \code{in\_tag} & \code{gt}    & \code{>}   & 13 \\
10 & \code{default} & \code{lt}    & \code{<}   & 14 \\
11 & \code{in\_tag} & \code{name}  & \code{c}   & 15 \\
12 & \code{in\_tag} & \code{gt}    & \code{>}   & 16 \\
13 & \code{default} & \code{text}  & \code{foo} & 17 \\
14 & \code{default} & \code{lt}    & \code{<}   & 20 \\
15 & \code{in\_tag} & \code{slash} & \code{/}   & 21 \\
16 & \code{in\_tag} & \code{name}  & \code{c}   & 22 \\
17 & \code{in\_tag} & \code{gt}    & \code{>}   & 23 \\
18 & \code{default} & \code{lt}    & \code{<}   & 24 \\
19 & \code{in\_tag} & \code{slash} & \code{/}   & 25 \\
20 & \code{in\_tag} & \code{name}  & \code{a}   & 26 \\
21 & \code{in\_tag} & \code{gt}    & \code{>}   & 27 \\
22 & \code{default} & \code{EOF}   & \code{}    & 29
\end{tabular}
\end{center}

\end{example}

L'analyseur syntaxique prend la suite en dérivant la séquence par rapport aux
règles de la grammaire. Cela consiste à dépiler les lexèmes de la séquence un
par un et de regarder si nous pouvons explorer les règles.

\begin{example}[Analyse syntaxique de \code{<a x="y"><b /><c>foo</c></a>}]
\label{example:data:syntactic_analyze}

Nous allons illustrer l'analyse syntaxique de la séquence obtenue dans
l'Exem\-ple~\ref{example:data:lexical_analyze}.

\begin{enumerate}

\item Nous allons dépiler le premier lexème~: \code{lt}. La règle \code{xml} est
composée de une ou plusieurs règles \code{tag}. La règle \code{tag} commence par
un lexème \code{lt}. Nous avons une correspondance, nous continuons.

\item Le deuxième lexème est \code{name}. La règle \code{tag} se poursuit avec
le lexème \code{name}, nous avons une correspondance. Le lexème \code{name}
porte une unification. Le prochain lexème \code{name} pour cette règle devra
avoir comme valeur \code{a}.

\item Nous continuons avec le troisième lexème de la séquence~: \code{name}. La
règle \code{tag} poursuit avec un appel à la règle \code{attributes} qui
commence avec le lexème \code{name}. Encore une fois, nous avons une
correspondance.

\item[4-5.] Pareil pour le quatrième (\code{equal}) et cinquième lexème
(\code{value}).

\item[6.] Le sixième lexème est \code{gt}. La règle \code{attributes} demande
soit d'avoir un nouvel attribut, soit nous avons atteint la fin de la règle, ce
qui est notre cas. Donc nous revenons dans la règle \code{tag}. Nous arrivons
dans une disjonction~: le premier élément ne peut pas dériver \code{gt} (il
attend \code{slash}), mais le second élément le permet. Nous avons une
correspondance, nous continuons.

\item[…] Nous passons au lexème suivant dans la séquence. Et ainsi de suite,
jusqu'à atteindre la fin de la séquence.

\end{enumerate}

\end{example}

Si nous ne pouvons plus dériver la séquence, nous allons revenir en arrière de
$k$-lexèmes jusqu'à retomber sur un point de choix (une disjonction ou une
répétition). Cette étape s'appelle le \inenglish{backtracking}. Dans notre cas,
$k$ est infixé, nous disons que nous revenons en arrière de $\star$-lexèmes,
soit d'autant de lexèmes que nécessaire.

La séquence est construite en analysant la donnée textuelle de gauche à droite
(\inenglish{{\strong L}eft to right}) et la séquence est dérivée en utilisant
toujours le lexème le plus à gauche de la séquence (\inenglish{{\strong
L}eftmost derivation}), nous avons donc un compilateur $LL(\star)$.

Une fois que la donnée a été validée par l'analyseur syntaxique, le compilateur
est capable de produire un AST, pour \inenglish{Abstract Syntax Tree}, soit un
arbre de syntaxe abstrait. Les constructions \code{\#node} dans la grammaire
permettent de forcer la création d'un nœud dont les enfants seront des nœuds ou
des lexèmes déclarés avec la syntaxe \code{<token>} (l'autre construction,
\code{::token::}, n'autorise pas les lexèmes à apparaître dans l'arbre). La
Figure~\ref{figure:data:ast} montre l'AST résultant des
Exemples~\ref{example:data:lexical_analyze} et
\ref{example:data:syntactic_analyze}.
%
\begin{figure}

\fig{\textwidth}{!}{AST.tex}

\caption{\label{figure:data:ast} Arbre de syntaxe abstrait de la donnée \code{<a x="y"><b
/><c>foo</c></a>}.}

\end{figure}
%
Un AST est une structure récursive. Nous pouvons lui appliquer un {\strong
visiteur}~\acite{design-patterns}. Ce \inenglish{design-pattern} permet à
l'utilisateur d'appliquer des traitements supplémentaires~: des contraintes qui
ne peuvent pas être représenter par la grammaire, comme par exemple une
vérification de typage. \\

Nous parlons de {\strong compilateur de compilateur} car la grammaire est tout
d'abord transformée en compilateur, c'est à dire en un analyseur lexical et un
syntaxique. La grammaire nous évite d'avoir à écrire un compilateur à la main. \\

Ce compilateur de compilateur $LL(\star)$ nous permet de valider une donnée
textuelle complexe. Ainsi, nous respectons la première caractéristique d'un
domaine réaliste~: la prédicabilité. Les sections suivantes illustrent plusieurs
algorithmes de générations à partir d'une grmmaire.

%\subsubsection{Utiliser PP avec le domaine réaliste \code{Grammar}}
%
%Une grammaire et sa technique classique de compilation associée permet d'assurer
%la caractéristique de prédicabilité d'un domaine réaliste, en vérifiant qu'une
%donnée est correctement structurée par rapport à une grammaire…
%
%\begin{pre}
%@requires payload: grammar('Json.pp');
%\end{pre}

\subsection{Algorithmes de génération de données à partir de grammaires}
\label{subsection:data:algorithms}

Nous décrivons maintenant l'utilisation de grammaires pour la génération de
données textuelles complexes, afin d'assurer la caractéristique de générabilité
des domaines réalistes.

Nous proposons trois algorithmes de générations différents~: aléatoire et
uniforme, exhaustive bornée et enfin basée sur la couverture. Le principe de
ces algorithmes est résumé dans la Figure~\ref{figure:data:grammar}.
%
\begin{figure}

\fig{\textwidth}{!}{Grammar_based_generation.tex}

\caption{\label{figure:data:grammar} Principe des algorithmes de générations de
données~: à partir d'une grammaire est extraite une séquence de lexème qui est
ensuite concrétisée vers un mot.}

\end{figure}
%
Ils vont générer différentes séquences de lexèmes à partir d'une grammaire, pour
ensuite les concrétiser vers une donnée textuelle. L'algorithme de
concrétisation est présenté en dernier.

Pour générer des séquences de lexèmes, les algorithmes vont explorer les règles
de la grammaire selon différentes contraintes~: la taille de la séquence, la
fréquence d'apparition des lexèmes, la quantité de séquences etc.

\subsubsection{Génération aléatoire et uniforme}
\label{subsection:data:random_uniform_generation}

Cet algorithme permet de générer des séquences de lexèmes de taille $n$ fixe.
Chaque séquence est générée aléatoirement et avec une distribution uniforme
parmi toutes les séquences possibles de taille $n$. Afin d'assurer cette
uniformité, nous allons nous baser sur les travaux de \acitei{FlajoletZC94}. Les
auteurs proposent une méthode de calcul récursive pour compter le nombre de
sous-structures de taille $n$. Ce dénombrement va nous permettre de calculer des
fonctions de répartition pour guider l'algorithme dans l'exploration des règles
à chaque point de choix rencontré.

À chaque construction du langage PP est associée une fonction de dénombrement
$\psi$ qui compte le nombre de sous-structures de taille $n$ qu'il est possible
de générer. Ainsi~:

\begin{align*}
%
\psi(n, e) & =
    \delta_n^1
    &
    \text{si $e$ est un lexème}
    \\
%
\psi(n, e_1 \cdot \dotso \cdot e_k) & =
    \sum_{\gamma \,\in\, \Gamma_k^n}
    \prod_{\alpha \,=\, 1}^k
    \psi(\gamma_\alpha, e_\alpha)
    \\
%
\psi(n, e_1 \,\vert\, \dots \,\vert\, e_k) & =
    \sum_{\alpha \,=\, 1}^k
    \psi(n, e_\alpha)
    \\
%
\psi(n, e^{\{x, y\}}) & =
    \sum_{\alpha = x}^y
    \sum_{\gamma \,\in\, \Gamma_\alpha^n}
    \prod_{\beta \,=\, 1}^\alpha
    \psi(\gamma_\beta, e)
    &
    \text{avec $0 \leq x \leq y$}
%
\end{align*}

Dans la première formule, $\delta_i^j$ est le symbole de Kronecker, défini
comme 1 si $i = j$, 0 sinon. $\Gamma_k^n$ désigne l'ensemble des $k$-uplets dont
la somme des éléments est égale à $n$. Pour chaque $k$-uplet $\gamma$ et chaque
$\alpha \in [1; k]$, $\gamma_\alpha$ désigne le $\alpha$\textsuperscript{ième}
élément de $\gamma$.
%
Par exemple~:
%
$$\Gamma_3^2 = \{(2, 0, 0), (1, 1, 0), (1, 0, 1), (0, 2, 0), (0, 1, 1), (0, 0,
2)\}$$
%
et pour le premier $k$-uplet, $\gamma_1 = 2$ et $\gamma_2 = \gamma_3 = 0$.

La concaténation, représentée par l'opérateur $\cdot$, somme la distribution de
$n$ parmi toutes les sous-structures. La disjonction, représentée par
l'opérateur $\vert$, somme la taille des sous-structures de taille $n$. Et
enfin, une répétition, représentée par $\{x, y\}$, est une disjonction de
concaténations (en effet, $e^{\{2,4\}} \Longleftrightarrow ee \,\vert\, eee
\,\vert\, eeee$). Quand $y$ est non-défini (avec \code{*} et \code{+}), il est
borné à $n$.

\begin{example}[Exploration aléatoire et uniforme]
\label{example:data:random_uniform_generation}

Soit la grammaire suivante~:

\begin{pre}
f: <a> g() \\
g: ( <b> <c> | <d> | f() )\{1,3\}
\end{pre}

Nous voulons compter le nombre de sous-structures possibles de taille 5. Nous
commençons avec $f(5)$ qui signifie~: le nombre de sous-structures de taille 5
que peut produire la règle \code{f}. Cette règle commence par un lexème
\code{<a>}, donc le reste de la séquence (donné par la règle \code{g}) devra
faire une taille de 4. Nous calculons alors $g(4)$. La règle \code{g} est une
répétition $r \in [1; 3]$ d'une disjonction. Avec $r = 1$, le seul moyen d'avoir
une sous-structure de taille 4 et de passer par \code{f}, donc nous devons
calculer $f(4)$. Avec $r = 2$, nous pouvons avoir \code{<b> <c> <b> <c>}, ou
\code{<b> <c>} puis $f(2)$, ou \code{<d>} puis $f(3)$ etc. Nous arrivons
finalement au tableau de la Figure~\ref{figure:data:random_tabular}.

\begin{figure}

\begin{center}
\begin{tabular}{lcccccccccccccc}
$n$ & \code{f:} & $\dots$ & \code{g:} & \code{(} &
  \code{<b> <c>} & \code{|} & \code{<d>} & \code{|} & \code{f()} & \code{)} &
  \multicolumn{3}{c}{\code{\{1, 3\}}} \\
\hline
\hline

& & & & & & & & & & $r = $ & 1 & 2 & 3 \\

\hline

5 & 24 & & 73 & 24 & 0 & & 0 & & - & & (24, & 28, & 21)\\
4 & 8  & & 24 & 8  & 0 & & 0 & & - & & (8, & 10, & 6) \\
3 & 3  & & 8  & 3  & 0 & & 0 & & - & & (3, & 4, & 1) \\
2 & 1  & & 3  & 2  & 1 & & 0 & & - & & (2, & 1, & 0) \\
1 & 0  & & 1  & 1  & 0 & & 1 & & - & & (1, & 0, & 0) \\

\hline

\end{tabular}
\end{center}

\caption{\label{figure:data:random_tabular} Tableau récapitulatif des résultats
de la fonction $\psi$. La première colonne montre les valeurs possibles de $n$.
La deuxième colonne montre les résultats pour $f(n)$. Ensuite, nous avons les
résultats pour $g(n)$, avec le détail~: pour la disjonction, pour chaque branche
de la disjonction, et ensuite pour la répétition avec $r = 1$, 2 et 3.}

\end{figure}

Maintenant, nous sommes outillés pour explorer la grammaire. Imaginons que nous
sommes sur l'exploration de la règle \code{g} avec $n = 3$. Nous avons une
répétition $r \in [1; 3]$. Nous savons grâce à notre fonction $\psi$ que $g(3) =
8$, c'est~à~dire que \code{g} peut produire 8 sous-structures de taille 3. Il
faut choisir aléatoirement et uniformément une valeur pour $r$, grâce aux
probabilités données par la fonction $\psi$~:

$$
p(r = 1) = \frac{3}{8} \qquad
p(r = 2) = \frac{4}{8} \qquad
p(r = 3) = \frac{1}{8}
$$

Ensuite, nous choisissons un entier $i \in [1; 8]$ aléatoirement et
uniformément. Disons que $i = 5$. Nous appliquons nos probabilités et nous
obtenons $r = 2$.
%
%\drawfig{6.5cm}{!}{}{
%
%  \draw[->] (-.1,   0) -- (7, 0) node[anchor=north] {$r$};
%  \draw[->] (  0, -.1) -- (0, 5) node[anchor=east]  {$n$};
%
%  \draw (1, 0) node[anchor=north] {1}
%        (3, 0) node[anchor=north] {2}
%        (5, 0) node[anchor=north] {3};
%
%  \draw (0, 1) node[anchor=east] {1}
%        (0, 2) node[anchor=east] {2}
%        (0, 3) node[anchor=east] {3}
%        (0, 4) node[anchor=east] {4};
%
%  \draw[thick] (0, 3) -- (2, 3)
%               (2, 4) -- (4, 4)
%               (4, 1) -- (6, 1)
%               (2, 0) -- (2, 4)
%               (4, 0) -- (4, 4)
%               (6, 0) -- (6, 1);
%
%  \draw (3, -1) node {$\afrac{\uparrow}{i}$};
%
%}
%
Donc nous allons répéter notre disjonction 2 fois. Nous sommes sur \code{g} avec
une taille de 3, donc nous avons 3 lexèmes à répartir sur 2 répétitions. Nous
utilisons la fonction $\Gamma$ pour calculer cette répartition~: $\Gamma_2^3 =
((2, 1), (1, 2))$ (tous les $k$-uplets contenant un 0 ont été supprimés car
c'est impossible de distribuer 0 lexème dans une répétition). Nous allons
utiliser soit 2 lexèmes lors de la répétition $r = 1$ et 1 lexème pour $r = 2$,
soit l'inverse. Nous choisissons un entier $j \in [1; 2]$ aléatoirement et
uniformément pour sélectionner le $k$-upplet. Disons que $j = 1$, donc nous
allons utiliser $(2, 1)$.

Pour la première répétition $r = 1$, nous avons $n = 2$ lexèmes à distribuer. La
disjonction peut produire 2 sous-structures. Nous avons besoin de calculer une
nouvelle fonction de répartition. La disjonction a trois branches~: la première
peut produire 1 sous-structure, la deuxième 0 et la dernière 1 sous-structure.
La probabilité de parcourir la première branche ou la dernière branche est de
$\tfrac{1}{2}$. Et ainsi de suite.

\end{example}

Cet algorithme est efficace pour nous calculer des petites séquences de taille
fixe avec beaucoup de diversités dans les résultats (puisqu'aléatoire).
Toutefois, l'étape du dénombrement avec la fonction $\psi$ est exponentielle. Et
malgré l'utilisation d'heuristiques inspirées de la programme dynamique, pour
une valeur de $n > 10$, au moins 2~heures de calculs sont nécessaires. Ce
problème ne concerne que la première étape, car la seconde étape, quand à elle,
est très rapide~: la génération d'une séquence est la plus rapide de tous les
algorithmes.

\subsubsection{Génération exhaustive bornée}
\label{subsection:data:bounded_exhaustive_generation}

Cet algorithme permet de générer toutes les séquences de lexèmes dont la taille
est au maximum $n$. C'est une génération exhaustive bornée. Des
expériences~\acite{MarinovK01, SullivanYCKJ04} ont montré que générer énormément
de données de façon exhaustive peut être efficace pour détecter des erreurs car
toutes les données sont testées.

À chaque construction du langage PP est associée une fonction $\beta$ qui va
nous calculer la prochaine séquence. Cet algorithme se comporte comme un
itérateur sur tous les éléments du multi-ensemble construits avec la fonction
$\beta$. Un multi-ensemble, noté avec $\amultiset{A}$, est un ensemble avec des
répétitions~: en effet, rien ne nous assure que la grammaire ne puisse pas
produire au moins deux séquences identiques mais par des dérivations/chemins
différents. Pour simplifier l'écriture de la fonction $\beta$, nous considérons
que la grammaire PP est en forme normale de Chomsky~\acite{Chomsky56}. Ainsi~:

\begin{align*}
%
\beta(1, e) & =
    \amultiset{e}
    &
    \text{si $e$ est un lexème}
    \\
%
\beta(n, e) & =
    \amultiset{}
    &
    \text{si $n \neq 1$}
    \\
%
\beta(n, e_1 \,\vert\, e_2) & =
    \beta(n, e_1) \union \beta(n, e_2)
    \\
%
\beta(n, e_1 \cdot e_2) & =
    \Union_{p = 1}^{n - 1}
    \beta(p, e_1) \cdot \beta(n - p, e_2)
    \\
%
\beta(n, e^{\{x, y\}}) & =
    \Union_{p = x}^y \beta(n, e_p)
    \\
%
\beta(n, e^*) & =
    \Union_{p = 0}^n \beta(n, e_p)
    \\
%
\beta(n, e^+) & =
    \beta(n, e \cdot e^*)
    \\
%
\beta(n, e^0) & =
    \amultiset{}
    \\
%
\beta(n, e^1) & =
    \beta(n, e)
    \\
%
\beta(n, e^p) & =
    \beta(n, e \cdot e^{p - 1})
    &
    \text{si $p \geq 2$}
%
\end{align*}

Les opérateurs $\union$ et $\Union$ correspondent à l'union des multi-ensembles.
Quand $y$ est non-défini (avec \code{*} et \code{+}), il est borné à $n$.

\begin{example}[Exploration exhaustive bornée]
\label{example:data:bounded_exhaustive_generation}

Soit la même grammaire que dans
l'Exemple~\ref{example:data:random_uniform_generation}, à savoir~:

\begin{pre}
f: <a> g() \\
g: ( <b> <c> | <d> | f() )\{1,3\}
\end{pre}

Nous allons dérouler l'algorithme pour $n = 10$. Nous commençons par explorer
la règle \code{f}. Nous produisons \code{<a>}, puis nous explorons la règle
\code{g} qui propose une répétition d'une disjonction.  Nous commençons par la
borne inférieure de la répétition puis la première branche de la disjonction,
soit \code{<b> <c>}. La première séquence est donc~: \code{<a> <b> <c>}. La
séquence suivante revient au dernier point de choix pour prendre le chemin
suivant, à savoir la deuxième branche de la disjonction. La deuxième séquence
est donc~: \code{<a> <d>}. Nous continuons avec le troisième point de choix de
la disjonction qui est la règle \code{f}. Nous reprenons un chemin équivalent~:
\code{<a>} puis \code{g}. Nous explorons à nouveau notre répétition, nous
choisissons la borne inférieure et le premier élément de la disjonction. La
troisième séquence est donc~: \code{<a> <a> <b> <c>}. Les séquences sont~:

\begin{enumerate}
\setcounter{enumi}{4}

\item \code{<a> <a> <d>}

\item \code{<a> <a> <a> <b> <c>}

\item \code{<a> <a> <a> <d>}

\item \code{<a> <a> <a> <a> <b> <c>}

\item[…] …

\item[12150.] \code{<a> <a> <a> <a> <a> <a> <a> <a> <a> <d>}

\end{enumerate}

\end{example}

Cet algorithme est rapide pour calculer des petites séquences et l'exhaustivité
est très efficace pour détecter des erreurs. Toutefois, le nombre de séquences
générables est exponentielle par rapport $n$ mais l'unité reste la seconde et
non pas l'heure comme avec l'algorithme précédent.

\subsubsection{Génération basée sur la couverture}
\label{subsection:data:coverage_based_generation}

Cet algorithme essaye de réduire l'explosition combinatoire de l'algorithme
précédent. Il va générer des séquences en respectant deux critères de
couvertures sur la grammaire~:
%
\begin{itemize}

\item une règle est dit couverte si et seulement toutes ses sous-règles ont été
couvertes~;

\item un lexème est dit couvert si il a été utilisé avec succès dans une
séquence.

\end{itemize}
%
Pour assurer une diversité dans les séquences générées, les points de choix sont
résolus aléatoirement parmi les sous-règles non-couvertes. Une heuristique est
utilisée pour borner les répétitions afin de réduire encore l'explosion
combinatoire et garantir la terminaison de l'algorithme. L'opérateur \code{*}
est borné à 0, 1 et 2, \code{+} est déplié 1 ou 2~fois, et $\{x, y\}$ est
déplié $x$, $x + 1$, $y - 1$ et $y$~fois.

À chaque construction du langage PP est associée une fonction $\phi$ qui va nous
calculer la prochaine séquence. Cette fonction prend en argument $p$, qui est le
préfixe de la séquene déjà produite (vide au départ). Cet algorithme se comporte
comme un itérateur Ainsi~:

\begin{align*}
%
\phi(p, e) & =
    [e]
    &
    \text{si $e$ est un lexème}
    \\
%
\phi(p, e_1 \cdot e_2) & =
    \phi(\phi(p, e_1), e_2)
    \\
%
\phi(p, e_1 \vert \dotso \vert e_k) & =
    \phi(p, e_1) \oplus \dotso \oplus \phi(p, e_k)
    \\
%
\phi(p, e^?) & =
    [] \oplus \phi(p, e)
    \\
%
\phi(p, e^*) & =
    [] \oplus \bigoplus_{i = 1}^\infty
    \phi(p, \underbrace{e \cdot \dotso \cdot e}_i)
    \\
%
\phi(p, e^+) & =
    \bigoplus_{i = 1}^\infty \phi(p, \underbrace{e \cdot \dotso \cdot e}_i)
    \\
%
\phi(p, e^{\{x, y\}}) & =
    \bigoplus_{i = x}^y \phi(p, \underbrace{e \cdot \dotso \cdot e}_i)
%
\end{align*}

Une séquence vide est représentée par $[]$. L'opérateur $\oplus$ désigne un
choix entre plusieurs appels récursifs de la fonction.

\begin{example}[Exploration basée sur la couverture]
\label{example:data:coverage_based_generation}

Soit la même grammaire que dans les exemples précédents, à savoir~:

\begin{pre}
f: <a> g() \\
g: ( <b> <c> | <d> | f() )\{1,3\}
\end{pre}

Nous commençons par explorer la règle \code{f}. Nous produisons \code{<a>} avant
d'explorer la règle \code{g}. Là, nous choisissons aléatoirement de répéter
3~fois la disjonction. La première fois, nous choisissons le lexème \code{<d>}.
La seconde fois, nous avons le choix entre \code{<b> <c>} ou \code{f}
(\code{<d>} ayant déjà été couvert, nous ne voulons pas le choisir). Nous
choisissons \code{<b> <c>}. Enfin, à la troisième répétition, il ne sert plus
qu'un choix pour la disjonction~: nous explorons \code{f} à nouveau. Nous
produisons \code{<a>} et nous continuons dans \code{g}. Là, tout a été couvert,
nous choisissions alors aléatoirement une répétition (disons 1), puis \code{<a>}
dans la disjonction. La séquence \code{<a> <d> <b> <c> <a> <d>} couvre toutes
les règles et tous les lexèmes de la grammaire.

\end{example}

Cet algorithme est rapide pour des séquences de taille moyenne ou grande. La
diversité entre les séquences générées est dû au choix aléatoire sur les points
de choix. Il génère peu de données mais il couvre toutes les règles et tous les
lexèmes. Enfin, contrairement aux algorithmes précédents, nous ne pouvons pas
contrôler la taille de la séquence.

\subsubsection{Concrétisation~: génération isotropique de lexèmes}
\label{subsection:data:isotropic_generation}

Les trois algorithmes génèrent des séquences de lexèmes, mais nous n'avons pas
de données concrètes. Pour cela, nous devons transformer les lexèmes en données
afin de produit un mot.

Nous rappelons que les lexèmes sont exprimés avec des expressions régulières au
format PCRE. Nous avons écrit la grammaire des PCRE avec PP. Ainsi, nous
analysons une expression régulière avec cette grammaire, le compilateur de
compilateur nous produit un AST que nous allons parcourir pour générer une
donnée. Ce processus est détaillé dans la Figure~\ref{figure:data:regex}.
%
\begin{figure}

\fig{\textwidth}{!}{Regex_to_word.tex}

\caption{\label{figure:data:regex} Fonctionnement de la concrétisation.}

\end{figure}
%
L'algorithme de génération est isotropique~: c'est à dire qu'il est aléatoire et
uniforme mais l'uniformité est locale à un point de choix, et non pas parmi
toutes les sous-structures possibles.

\begin{example}[Génération isotropique]

Soit l'expression régulière suivante~:

$$\code{([ae]+|[x-y]!)\{1,3\}}$$

\begin{tabular}{ll}

\code{\ingray{([ae]+|[x-y]!)}\{1,3\}} & bla bla \\
\code{([ae]+|[x-y]!)\ingray{([ae]+|[x-y]!)}} & bla bla \\
\code{([ae]+)\ingray{([ae]+|[x-y]!)}} & bla bla \\
\code{[ae][ae]\ingray{([ae]+|[x-y]!)}} & bla bla \\
\code{e[ae]\ingray{([ae]+|[x-y]!)}} & bla bla \\
\code{ea\ingray{([ae]+|[x-y]!)}} & bla bla \\
\code{\ingray{ea}([x-y]!)} & bla bla \\
\code{eay!} & bla bla

\end{tabular}

\end{example}
