\section{Génération à partir de grammaire pour les chaînes de caractères}
\label{section:data:strings}

Une grammaire est utilisée pour représenter des données textuelles complexes.  À
l'aide d'un compilateur, nous allons nous assurer qu'une donnée (textuelle) est
conforme à une grammaire. C'est une propriété sur deux d'un domaine réaliste~:
ce qui fait des grammaires de bonnes candidates pour être une base d'un domaine
réaliste.

Nous allons en premier lieu nous concentrer sur la première caractéristique des
domaines réalistes, à savoir la prédicabilité, et présenter un langage simple de
description de grammaire ainsi que son interprétation avec un compilateur de
compilateur dédié. Ensuite, nous allons voir comment exploiter une grammaire
pour générer des données valides.

\subsection{Langage de description de grammaire}
\label{subsection:data:pp}

Une grammaire est constituée de {\strong lexèmes}, unités atomiques lexicales
d'une langue, et de {\strong règles} exprimant l'enchaînement possible des
lexèmes les uns par rapport aux autres. Le langage \inenglish{PHP Parser},
abrégé PP, est utilisé pour exprimer des grammaires \inenglish{top-down} et
algébriques. La syntaxe est principalement inspirée de YACC~\acite{Johnson75} et
JavaCC avec l'ajout de nouvelles constructions.

La déclaration d'un lexème est de la forme suivante~:

\begin{pre}
%token ns_source:name value -> ns_dest
\end{pre}
%
où \code{name} représente son nom, \code{value} sa valeur exprimée avec une
expression régulière, et \code{ns\_source} et \code{ns\_dest} sont des espaces
de nom optionnels. Les expressions régulières sont écrites en utilisant la
syntaxe standard des PCRE~\acite{Hazel05}, très expressives, largement utilisées
et supportées (par exemple dans PHP, Javascript, Perl, Python, Apache, KDE
etc.). Les espaces de noms servent à représenter des sous-ensembles disjoints de
lexèmes pour la phase d'analyse lexicale (détaillée ci-après). Une déclaration
\code{\%skip} est similaire à une déclaration \code{\%token} excepté qu'elle
représente un lexème à «~sauter~», c'est~à~dire à ne pas retenir dans la
séquence de lexèmes.

\begin{figure}

\begin{bigpre}
%skip          space    \(\bslash\)s \\
%token         lt       <        -> in_tag \\
%token         text     [^<]* \\
%skip   in_tag:space    \(\bslash\)s \\
%token  in_tag:name     \(\bslash\)w+ \\
%token  in_tag:slash    / \\
%token  in_tag:gt       >        -> default \\
%token  in_tag:equal    = \\
%token  in_tag:value    ".*?(?<!\(\bslash\bslash\))" \\
\\
xml: \\
    tag()+ #root \\
tag: \\
    ::lt:: <name[0]> attributes() \\
    ( \\
      ::slash:: ::gt:: #atomic \\
    | ::gt:: ( <text> #textual | tag() #composite )* \\
      ::lt:: ::slash:: ::name[0]:: ::gt:: \\
    ) \\
#attributes: \\
    ( <name> ::equal:: <value> )*
\end{bigpre}

\caption{\label{figure:data:xml} Grammaire simplifiée d'un document XML.}

\end{figure}

La Figure~\ref{figure:data:xml} montre un exemple d'une grammaire simplifiée
d'un document XML. Elle commence par la déclaration des lexèmes, en utilisant
des espaces de noms pour identifier si l'analyse se déroule à l'extérieur ou à
l'intérieur d'une balise. La règle \code{xml} décrit un document XML comme une
séquence de balises, chaque balise ayant potentiellement des attributs et étant
atomique (\code{<aTag />}), composite (contenant d'autres balises) ou contenant
du texte (\code{<aTag>with text</aTag>}). Un nom de règle (\code{xml},
\code{tag} ou \code{attribute} dans la Figure~\ref{figure:data:xml}) est suivi
du symbole \code{:}, puis d'une nouvelle ligne, immédiatement suivie par une
{\strong déclaration de règle}, préfixée par des caractères blancs horizontaux
(espaces ou tabulations). Les lexèmes peuvent être référencés en utilisant deux
types de constructions. La construction \code{::token::} signifie que le lexème
ne sera pas conservé à la fin du processus de compilation (détaillé ci-après),
contrairement à la construction \code{<token>}. La construction \code{rule()}
représente un appel à une règle.  Les opérations de répétition sont classiques:
\code{\{$x$, $y$\}} pour répéter le motif $x$ à $y$ fois, \code{?} est identique
à \code{\{0, 1\}}, \code{+} à \code{\{1, \}}, \code{*} à \code{\{0, \}}. Les
disjonctions sont représentées par le symbole \code{\mvert} et le groupement par
\code{(} et \code{)}. La construction \code{\#node} (parfois utilisé comme nom
de règle) est utile pour la fin du processus de compilation.

Si un lexème est suivi de \code{[$i$]} avec $i \geq 0$, nous avons une
unification. C'est une nouvelle construction. Une unification pour les lexèmes
implique que tous les \code{token[$i$]} avec le même $i$ ont la même valeur
localement à la règle.  Remarquons la présence d'une unification de lexème dans
la Figure~\ref{figure:data:xml}~: \code{name[0]} indique que la balise
d'ouverture et de fermeture doivent avoir le même nom. Ainsi, la donnée
\code{<foo>…</foo>} sera considérée comme valide, alors que \code{<foo>…</bar>}
sera considérée comme invalide. Un autre usage courant est la gestion des
guillemets représenté par le lexème \code{\%token quote '|"}, soit un guillemet simple, soit
un double. Ainsi, \code{"…"} comme \code{'…'} doivent être valides, alors que
\code{"…'} ou \code{'…"} devront être invalides. Pour cela, nous écrirons par
exemple \code{quote[1]} dans une règle.

Si un espace de nom source n'est pas précisé, alors il prendra la valeur
\code{default}, qui est l'espace de nom par défaut. L'espace de nom de
destination peut être de la forme spéciale \code{\_\_shift\_\_ * $j$}, avec $j
\geq 1$, pour revenir $j$ espaces de nom en arrière. En effet, il est parfois
possible d'accéder à un lexème depuis plusieurs espaces de nom différents. Cette
forme spéciale répond à cette problématique. \\

Nous trouverons la grammaire du langage PP en langage PP dans la
Figure~\ref{figure:appendices:grammar_of_pp} à la
page~\pageref{figure:appendices:grammar_of_pp}.

\subsection{Compilateur de compilateur $LL(\star)$}
\label{subsection:data:compiler-compiler}

Le fonctionnement schématique d'un compilateur est présenté dans la
Figure~\ref{figure:data:compiler}. À partir d'un {\strong mot} (d'une donnée
textuelle), nous allons extraire une {\strong séquence} de lexèmes grâce à
l'analyseur lexical. Ensuite, cette séquence sera {\strong dérivée} grâce à
l'analyseur syntaxique pour savoir si elle est valide ou non.
%
\begin{figure}

\fig{\textwidth}{!}{Compiler.tex}

\caption{\label{figure:data:compiler} Fonctionnement d'un compilateur~: un mot
est transformé en séquence de lexèmes grâce à une analyse lexicale. Et cette
séquence est validée ou invalidée grâce à une analyse syntaxique.}

\end{figure}
%
L'analyseur lexicale va appliquer, dans l'ordre de déclaration, tous les lexèmes
de l'espace de nom courant sur le début du mot jusqu'à trouver un lexème valide
(reconnaissant le début du mot). Le début du mot reconnu est supprimé pour être
ajouté à la suite de la séquence, avec des données supplémentaires (espace de
nom, numéro de lignes, de colonnes etc.). L'espace de nom est actualisé et
l'analyseur recommence jusqu'à atteindre la fin du mot. Si aucun lexème ne
permet de reconnaître le début du mot, alors une erreur sera levée.

\begin{example}[Analyse lexicale de \code{<a x="y"><b /><c>foo</c></a>}]
\label{example:data:lexical_analyze}

Avec la grammaire de la Figure~\ref{figure:data:xml}, l'analyse lexicale de la
donnée~:
%
$$\code{<a x="y"><b /><c>foo</c></a>}$$
%
produit la séquence suivante~:
\begin{center}
\begin{tabular}{rlllr}
   & espace de nom  & lexème       & valeur     & position \\
0  & \code{default} & \code{lt}    & \code{<}   & 0 \\
1  & \code{in\_tag} & \code{name}  & \code{a}   & 1 \\
2  & \code{in\_tag} & \code{name}  & \code{x}   & 3 \\
3  & \code{in\_tag} & \code{equal} & \code{=}   & 4 \\
4  & \code{in\_tag} & \code{value} & \code{"y"} & 5 \\
5  & \code{in\_tag} & \code{gt}    & \code{>}   & 8 \\
6  & \code{default} & \code{lt}    & \code{<}   & 9 \\
7  & \code{in\_tag} & \code{name}  & \code{b}   & 10 \\
8  & \code{in\_tag} & \code{slash} & \code{/}   & 12 \\
9  & \code{in\_tag} & \code{gt}    & \code{>}   & 13 \\
10 & \code{default} & \code{lt}    & \code{<}   & 14 \\
11 & \code{in\_tag} & \code{name}  & \code{c}   & 15 \\
12 & \code{in\_tag} & \code{gt}    & \code{>}   & 16 \\
13 & \code{default} & \code{text}  & \code{foo} & 17 \\
14 & \code{default} & \code{lt}    & \code{<}   & 20 \\
15 & \code{in\_tag} & \code{slash} & \code{/}   & 21 \\
16 & \code{in\_tag} & \code{name}  & \code{c}   & 22 \\
17 & \code{in\_tag} & \code{gt}    & \code{>}   & 23 \\
18 & \code{default} & \code{lt}    & \code{<}   & 24 \\
19 & \code{in\_tag} & \code{slash} & \code{/}   & 25 \\
20 & \code{in\_tag} & \code{name}  & \code{a}   & 26 \\
21 & \code{in\_tag} & \code{gt}    & \code{>}   & 27 \\
22 & \code{default} & \code{EOF}   & \code{}    & 29
\end{tabular}
\end{center}

\end{example}

L'analyseur syntaxique prend la suite en dérivant la séquence par rapport à la
grammaire. Cela consiste à dépiler les lexèmes de la séquence un par un et de
regarder si nous pouvons explorer les règles.

\begin{example}[Analyse syntaxique de \code{<a x="y"><b /><c>foo</c></a>}]
\label{example:data:syntactic_analyze}

Nous allons illustrer l'analyse syntaxique de la séquence obtenue dans
l'Exem\-ple~\ref{example:data:lexical_analyze}.

\begin{enumerate}

\item Nous allons dépiler le premier lexème~: \code{lt}. La règle \code{xml} est
composée de une ou plusieurs règles \code{tag}. La règle \code{tag} commence par
un lexème \code{lt}. Nous avons une correspondance, nous continuons.

\item Le deuxième lexème est \code{name}. La règle \code{tag} se poursuit avec
le lexème \code{name}, nous avons une correspondance. Le lexème \code{name}
porte une unification. Le prochain lexème \code{name} pour cette règle devra
avoir comme valeur \code{a}.

\item Nous continuons avec le troisième lexème de la séquence~: \code{x}. La
règle \code{tag} poursuit avec un appel à la règle \code{attributes} qui
commence avec le lexème \code{name}. Encore une fois, nous avons une
correspondance.

\item[4-5.] Pareil pour le quatrième et cinquième lexèmes.

\item[6.] Le sixième lexème est \code{gt}. La règle \code{attributes} demande à
soit avoir un nouvel attribut, soit nous avons atteint la fin de la règle, ce
qui est notre cas. Donc nous revenons dans la règle \code{tag}. Nous arrivons
dans une disjonction~: le premier élément ne peut pas dériver \code{gt} (il
attend \code{slash}), mais le second élément le permet. Nous avons une
correspondance.

\item[…] Nous passons au lexème suivant dans la séquence. Et ainsi de suite,
jusqu'à atteindre la fin de la séquence.

\end{enumerate}

\end{example}

Si nous ne pouvons plus dériver la séquence, nous allons revenir en arrière
(cette étape s'appelle le \inenglish{backtracking}) de $k$-lexèmes jusqu'à
retomber sur un point de choix (une disjonction ou une répétition). Dans notre
cas, $k$ est infixé, nous disons que nous revenons en arrière de
$\star$-lexèmes, soit de autant de lexèmes que nécessaires.

La séquence est construite en analysant la donnée textuelle de gauche à droite
(\inenglish{{\strong L}eft to right}) et la séquence est dérivée en utilisant
toujours le lexème le plus à gauche de la séquence (\inenglish{{\strong
L}eftmost derivation}), nous avons donc un compilateur $LL(\star)$.

Une fois que la donnée a été validée par l'analyseur syntaxique, le compilateur
est capable de produire un AST, pour \inenglish{Abstract Syntax Tree}, soit un
arbre de syntaxe abstrait. Les constructions \code{\#node} dans la grammaire
permettent de forcer la création d'un nœud dont les enfants seront les lexèmes
déclarés avec la syntaxe \code{<token>} (l'autre construction
—~\code{::token::}~— n'autorise pas les lexèmes à apparaître dans l'arbre). La
Figure~\ref{figure:data:ast} montre l'AST résultant des
Exemples~\ref{example:data:lexical_analyze} et
\ref{example:data:syntactic_analyze}. \\

\begin{figure}

\fig{\textwidth}{!}{AST.tex}

\caption{\label{figure:data:ast} Arbre de syntaxe abstrait de la donnée \code{<a x="y"><b
/><c>foo</c></a>}.}

\end{figure}

Nous parlons de {\strong compilateur de compilateur} car la grammaire est tout
d'abord transformée en compilateur, c'est à dire en un analyseur lexical et un
syntaxique. La grammaire nous évite d'avoir à écrire un compilateur à la main.

\subsubsection{Utiliser PP avec le domaine réaliste \code{Grammar}}

Une grammaire et sa technique classique de compilation associée permet d'assurer
la caractéristique de prédicabilité d'un domaine réaliste, en vérifiant qu'une
donnée est correctement structurée par rapport à une grammaire…

\begin{pre}
@requires payload: grammar('Json.pp');
\end{pre}

\subsection{Algorithmes de génération de données à partir de grammaires}
\label{subsection:data:algorithms}

Nous décrivons maintenant l'utilisation de grammaire pour la génération de
données textuelles complexes, afin d'assurer la caractéristique de générabilité
des domaines réalistes.

Nous proposons pour le domaine réaliste \code{Grammar} trois algorithmes
différents~: un génération aléatoire uniforme, un 

\subsubsection{Génération isotropique de lexèmes}
\label{subsection:data:isotropic_generation}

\subsubsection{Génération aléatoire et uniforme}
\label{subsection:data:random_uniform_generation}

Sans autre critère de génération que la grammaire et la taille de la donnée à
générer, la génération aléatoire et uniforme peut être retenue comme stratégie.
Nous attentions que le choix soit non-biaisé, avec une distribution des
probabilités qui soit uniforme parmis toutes les données générées possibles.
Pour un…

À chaque construction du langage PP est associée une fonction de dénombrement
$\psi$ qui compte le nombre de sous-structures de taille $n$ qu'il est possible
de générer. Ainsi~:

\begin{align*}
%
\psi(n, e) & =
    \delta_n^1
    &
    \text{si $e$ est un lexème}
    \\
%
\psi(n, e_1 \cdot \dotso \cdot e_k) & =
    \sum_{\gamma \in \Gamma_k^n}
    \prod_{\alpha = 1}^k
    \psi(\gamma_\alpha, e_\alpha)
    \\
%
\psi(n, e_1 \vert \dots \vert e_k) & =
    \sum_{\alpha = 1}^k
    \psi(n, e_\alpha)
    \\
%
\psi(n, e^{\{x, y\}}) & =
    \sum_{\alpha = x}^y
    \sum_{\gamma \in \Gamma_\alpha^n}
    \prod_{\beta = 1}^\alpha
    \psi(\gamma_\beta, e)
    &
    \text{avec $0 \leq x \leq y$}
%
\end{align*}

Dans la première formule, $\delta_i^j$ est le symbole de Kronecker, définie
comme 1 si $i = j$, 0 sinon. $\Gamma_k^n$ désigne l'ensemble des $k$-uplets dont
la somme des éléments est $n$. Par exemple, $\Gamma_3^2 = \{(2, 0, 0), (1, 1,
0), (1, 0, 1), (0, 2, 0), (0, 1, 1), (0, 0, 2)\}$. Pour chaque $k$-uplet
$\gamma$ et chaque $\alpha$ dans $\{1, \dotso, k\}$, $\gamma_\alpha$ désigne le
$\alpha$\textsuperscript{ième} élément de $\gamma$. Pour chaque opérateur:

\begin{itemize}

\item la concaténation $\cdot$ somme la distribution de $n$ parmis toutes les
sous-constructions~;

\item la disjonction $\vert$ somme les sous-constructions de taille $n$~;

\item la répétition $\{x, y\}$ est une disjonction de concaténations.

\end{itemize}

Pour explorer une règle, nous utilisons des poids représentant le nombre de
sous-structures pour chaque sous-règle. Alors, nous choisissons uniformément et
aléatoirement un nombre pour sélectionner la prochaine sous-règle à explorer en
fonction de son poids.

\subsubsection{Génération exhaustive bornée}
\label{subsection:data:bounded_exaustive_generation}

\begin{align*}
%
\beta(1, e) & =
    \{\code{sample($e$)}\}
    &
    \text{si $e$ est un lexème}
    \\
%
\beta(n, e) & =
    \{\}
    &
    \text{si $n \neq 1$}
    \\
%
\beta(n, e_1 \vert e_2) & =
    \beta(n, e_1) \union \beta(n, e_2)
    \\
%
\beta(n, e_1 \cdot e_2) & =
    \Union_{p = 1}^{n - 1}
    \beta(p, e_1) \cdot \beta(n - p, e_2)
    \\
%
\beta(n, e^{\{x, y\}}) & =
    \Union_{p = x}^y \beta(n, e_p)
    \\
%
\beta(n, e^*) & =
    \Union_{p = 0}^n \beta(n, e_p)
    \\
%
\beta(n, e^+) & =
    \beta(n, e \cdot e^*)
    \\
%
\beta(n, e^0) & =
    \{\}
    \\
%
\beta(n, e^1) & =
    \beta(n, e)
    \\
%
\beta(n, e^p) & =
    \beta(n, e \cdot e^{p - 1})
    &
    \text{si $p \geq 2$}
%
\end{align*}

\subsubsection{Génération basée sur la couverture}
\label{subsection:data:coverage_based_generation}

\begin{align*}
%
\phi(p, e) & =
    [\code{sample($e$)}]
    &
    \text{si $e$ est un lexème}
    \\
%
\phi(p, e_1 \cdot e_2) & =
    \phi(\phi(p, e_1), e_2)
    \\
%
\phi(p, e_1 \vert \dotso \vert e_k) & =
    \phi(p, e_1) \oplus \dotso \oplus \phi(p, e_k)
    \\
%
\phi(p, e^?) & =
    [] \oplus \phi(p, e)
    \\
%
\phi(p, e^*) & =
    [] \oplus \bigoplus_{i = 1}^\infty
    \phi(p, \underbrace{e \cdot \dotso \cdot e}_i)
    \\
%
\phi(p, e^+) & =
    \bigoplus_{i = 1}^\infty \phi(p, \underbrace{e \cdot \dotso \cdot e}_i)
    \\
%
\phi(p, e^{\{x, y\}}) & =
    \bigoplus_{i = x}^y \phi(p, \underbrace{e \cdot \dotso \cdot e}_i)
%
\end{align*}
