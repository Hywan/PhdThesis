\section{Génération à partir de grammaire pour les chaînes de caractères}
\label{section:data:strings}

Une grammaire formelle permet de décrire avec précisions des données textuelles
complexes. Nous proposons des domaines réalistes de chaînes de caractères
définis par une grammaire. Des analyseurs lexicaux et syntaxiques permettent de
s'assurer qu'une chaîne de caractères est conforme à une grammaire. C'est une
caractéristique sur deux d'un domaine réaliste~: ce qui fait des grammaires de
bonnes candidates pour être un domaine réaliste.

Nous allons, dans les parties~\ref{subsection:data:pp} et
\ref{subsection:data:compiler-compiler}, nous concentrer sur la première
caractéristique des domaines réalistes, à savoir la prédicabilité, et présenter
un langage simple de description de grammaire que nous avons créé, ainsi que son
interprétation avec un compilateur de compilateur dédié. Ensuite, dans la
partie~\ref{subsection:data:algorithms}, nous allons voir comment exploiter une
grammaire pour générer des données valides, et ainsi assurer la seconde
caractéristique des domaines réalistes, à savoir la générabilité.

\subsection{Langage de description de grammaire}
\label{subsection:data:pp}

\begin{definition}[Grammaire]

Une grammaire est définie par un quadruplet $G = (\Sigma, N, P, S)$, où~:
%
\begin{itemize}

\item $\Sigma$ est l'ensemble fini de {\strong symboles terminaux} disjoint de
$N$~; aussi appelés {\strong lexèmes}, ce sont les unités atomiques lexicales
d'une langue~;

\item $N$ est l'ensemble fini de {\strong symboles non-terminaux}~;

\item $P$ est l'ensemble fini des {\strong règles de production} de la forme
$(\Sigma \union N)^* N (\Sigma \union N)^* \rightarrow (\Sigma \union N)^*$,
avec $^*$ représentant l'étoile de Kleene et $\union$ représentant l'union
d'ensembles~; les règles expriment l'enchaînement possible des lexèmes les uns
par rapport aux autres~;

\item $S \in N$ est l'axiome de la grammaire, le symbole indiquant le point de
départ de lecture de la grammaire.

\end{itemize}

\end{definition}

Selon la hiérarchie de Chomsky~\acite{Chomsky56}, les grammaires sont classées
en quatre niveaux~:
%
\begin{enumerate}

\item grammaires {\strong générales}, ou \inenglish{unrestricted grammars},
reconnaissant les langages dits de Turing, aucune restriction n'est imposée sur
les règles~;

\item grammaires {\strong contextuelles}, ou \inenglish{context-sensitive
grammars}, reconnaissant les langages contextuels~;

\item grammaires {\strong algébriques}, ou \inenglish{context-free grammars},
reconnaissant les langages algébriques, basés sur les automates à pile~;

\item grammaires {\strong régulières}, ou \inenglish{regular grammars},
reconnaissant les langages réguliers.

\end{enumerate}
%
Chaque niveau reconnaît le niveau suivant.

Nous proposons le langage \inenglish{PHP Parser}, abrégé PP, pour exprimer des
grammaires algébriques (et donc également régulières). Sa syntaxe est
principalement inspirée de JavaCC~\acite{javacc} et un peu de
YACC~\acite{Johnson75}, avec l'ajout de nouvelles constructions. La déclaration
d'un lexème est de la forme suivante~:
%
\begin{pre}
%token ns_source:name value -> ns_dest
\end{pre}
%
où \code{name} représente son nom, \code{value} sa valeur exprimée avec une
expression régulière, et \code{ns\_source} et \code{ns\_dest} sont des espaces
de noms optionnels. Les expressions régulières sont écrites en utilisant la
syntaxe standard des \inenglish{Perl Compatible Regular Expressions}, abrégé
PCRE~\acite{Hazel05}, très expressives, largement utilisées et supportées (par
exemple dans PHP, Javascript, Perl, Python, Apache, KDE etc.). Les espaces de
noms servent à représenter des sous-ensembles disjoints de lexèmes pour la phase
d'analyse lexicale (détaillée ci-après). Une déclaration \code{\%skip} est
similaire à une déclaration \code{\%token} excepté qu'elle représente un lexème
à ne pas retenir pour la suite. Typiquement les espaces dans une expression
arithmétique n'ont pas d'importance, nous pouvons ne pas les retenir, ils
n'apportent rien à l'expression. Si un espace de noms source n'est pas précisé,
alors il prendra la valeur \code{default}, qui est l'espace de noms par défaut.
L'espace de noms de destination peut être de la forme spéciale
\code{\_\_shift\_\_ * $j$}, avec $j \geq 1$, ou simplement \code{\_\_shift\_\_}
(équivalent à avoir $j = 1$), pour revenir de $j$ espaces de noms précédents. Il
est parfois possible d'accéder à un lexème depuis plusieurs espaces de noms
différents~; cette forme spéciale permet de revenir dans les espaces de noms
d'origine. \\

\begin{figure}

\begin{bigpre}
%skip          space    \(\bslash\)s \\
%token         lt       <            -> in_tag \\
%token         text     [^<]* \\
%skip   in_tag:space    \(\bslash\)s \\
%token  in_tag:name     \(\bslash\)w+ \\
%token  in_tag:slash    / \\
%token  in_tag:gt       >            -> default \\
%token  in_tag:equal    = \\
%token  in_tag:value    ".*?(?<!\(\bslash\bslash\))" \\
\\
xml: \\
    tag()+ #root \\
tag: \\
    ::lt:: <name[0]> attributes() \\
    ( \\
      ::slash:: ::gt:: #atomic \\
    | ::gt:: ( tag()+ #composite | <text> #textual )? \\
      ::lt:: ::slash:: ::name[0]:: ::gt:: \\
    ) \\
#attributes: \\
    ( <name> ::equal:: <value> )*
\end{bigpre}

\caption{\label{figure:data:xml} Grammaire simplifiée d'un document XML.}

\end{figure}

La figure~\ref{figure:data:xml} montre l'exemple des règles de productions $P$
d'une grammaire $(\Sigma, N, P, S)$ simplifiée d'un document XML~\acite{xml}.
Elle commence par la déclaration des lexèmes, en utilisant des espaces de noms
pour identifier si l'analyse se déroule à l'extérieur ou à l'intérieur d'une
balise. Nous avons alors~:
%
\begin{align*}
\Sigma = \{ & \code{space}, \code{lt}, \code{text}, \code{in\_tag:space},
              \code{in\_tag:name}, \\
            & \code{in\_tag:slash}, \code{in\_tag:gt}, \code{in\_tag:equal},
              \code{in\_tag:value} \}
\end{align*}
%
Nous avons aussi les non-terminaux~:
%
$$N = \{\code{xml}, \code{tag}, \code{attributes}\}$$
%
La règle \code{xml} est l'axiome de la grammaire, $S = \code{xml}$, car c'est la
première règle déclarée. Elle décrit un document XML comme une séquence de
balises, chaque balise ayant potentiellement des attributs et étant atomique
(\code{<aTag />}), composite (contenant d'autres balises), contenant du texte
(\code{<aTag>with text</aTag>}) ou étant vide. Un nom de règle (un non-terminal)
est suivi du symbole \code{:} puis d'une nouvelle ligne, immédiatement suivie
par une règle de production, préfixée par des caractères blancs horizontaux
(espaces ou tabulations). Les lexèmes peuvent être référencés en utilisant deux
types de constructions. La construction \code{::token::} signifie que le lexème
ne sera pas conservé à la fin du processus de compilation (détaillé ci-après),
contrairement à la construction \code{<token>}. La construction \code{rule()}
représente un appel à une règle. Évidemment, nous pouvons avoir des appels
récursifs. Les opérations de répétition sont classiques: \code{\{$x$, $y$\}}
pour répéter le motif de $x$ à $y$ fois, \code{?} est identique à \code{\{0,
1\}}, \code{+} à \code{\{1, \}}, \code{*} à \code{\{0, \}}. Quand $y$ est vide,
cela signifie l'infini. Les disjonctions sont représentées par le symbole
\code{\mvert} et le groupement par \code{(} et \code{)}. La construction
\code{\#node} (parfois utilisé comme nom de règle) est utile pour la fin du
processus de compilation, comme nous le verrons dans la partie suivante.

Une nouvelle construction présente dans le langage PP, par rapport aux langages
de descriptions de gramaires existants, est l'unification. Présente uniquement
sur les lexèmes, elle impose que tous les \code{token[$i$]} avec le même $i$ ont
la même valeur localement à la règle, avec $i \geq 0$.  Remarquons la présence
d'une unification de lexèmes dans la figure~\ref{figure:data:xml}~:
\code{name[0]} indique que les balises d'ouverture et de fermeture doivent avoir
le même nom. Ainsi, la donnée \code{<foo>…</foo>} sera considérée comme valide,
alors que \code{<foo>…</bar>} sera considérée comme invalide. Un autre usage
courant est la gestion des guillemets représentés par le lexème \code{\%token
quote '|"}, soit un guillemet simple, soit un double. Ainsi, \code{"…"} comme
\code{'…'} doivent être valides, alors que \code{"…'} ou \code{'…"} devront être
invalides. Pour cela, nous écrirons par exemple \code{quote[1]} dans une règle.

Nous trouverons la grammaire du langage PP en langage PP dans
l'annexe~\ref{appendices:grammar_of_pp} à la
page~\pageref{appendices:grammar_of_pp}.

\subsection{Compilateur de compilateur $LL(\star)$}
\label{subsection:data:compiler-compiler}

Le fonctionnement schématique d'un compilateur est présenté dans la
figure~\ref{figure:data:compiler}. À partir d'un {\strong mot} (d'une donnée
textuelle), nous allons extraire une {\strong séquence} de lexèmes grâce à
l'analyseur {\strong lexical}. Ensuite, cette séquence sera {\strong dérivée}
grâce à l'analyseur {\strong syntaxique} pour savoir si elle est valide ou non.
Un \inenglish{Abstract Syntax Tree}, abrégé AST, sera produit (détaillé
ci-après).
%
\begin{figure}

\fig{\textwidth}{!}{Compiler.tex}

\caption{\label{figure:data:compiler} Fonctionnement d'un compilateur.}

\end{figure}
%
Nous parlons de {\strong compilateur de compilateur} car la grammaire est tout
d'abord transformée en compilateur, c'est à dire en un analyseur lexical et un
syntaxique. La grammaire nous évite d'avoir à écrire un compilateur à la main.

Nous expliquons le fonctionnement de l'analyseur lexical par l'algorithme dans
la figure~\ref{figure:data:algo_lexer}. À partir d'une donnée textuelle (mot),
nous allons calculer une séquence de lexèmes. Nous allons appliquer toutes les
expressions régulières des lexèmes de l'espace de noms courant les uns après les
autres sur le début du mot jusqu'à trouver un lexème valide (reconnaissant le
début du mot). Quand un lexème est trouvé, nous lui associons certaines données,
comme son nom, sa valeur, sa position et son espace de noms. Ensuite, nous
mettons à jour l'espace de noms courant à partir de l'espace de noms sortant du
lexème (soit un nom d'espace, soit le mot-clé \code{\_\_shift\_\_ * $j$}). Si
aucun lexème n'est trouvé, une erreur sera levée, sinon nous ajoutons le lexème
à la séquence et nous continuons jusqu'à atteindre la fin de la donnée analysée.

\begin{figure}

\begin{algorithmic}[1]

\State $\astruct{Token}\{
    \avar{name}: \atype{string},
    \avar{value}: \atype{string},
    \avar{at}: \atype{integer},
    \avar{namespace}: \atype{string}
\}$

\Function{$\akw{Lexer}$}{}

  \Require $\avar{word}: \atype{string}$
  \Require $\avar{tokens}: \atype{map\astype{string, \atype{map}\astype{string, (regex, string)}}}$
  \Ensure  $\avar{sequence}: \atype{list\astype{Token}} \gets []$

  \State $\avar{namespace}: \atype{string} \gets \astring{'default'}$
  \State $\avar{namespaceStack}: \atype{stack\astype{string}} \gets []$
  \State $\avar{offset}: \atype{integer} \gets 0$
  \State $\avar{nextToken}: \atype{Token}$

  \While{$\avar{offset} \leq \avar{word}.\acall{length()}$}

      \State $\avar{nextToken} \gets \akw{null}$

      \ForAll{$\{\avar{name}, \avar{regex}, \avar{namespace\_out}\} \in \avar{tokens[namespace]}$}

          \If{$\avar{word} \akw{matches} \avar{regex} \akw{at} \avar{offset} \asets \avar{value}$}

              \State $\avar{nextToken} \gets \atype{Token}\{\avar{name}, \avar{value}, \avar{offset}, \avar{namespace}\}$

              \If{$\avar{namespace\_out} \akw{matches} \astring{'\_\_shift\_\_ * \mathit{j}'}$}

                  \State $\avar{j}.\acall{times}(\avar{namespaceStack}.\acall{pop})$

              \Else

                  \State $\avar{namespaceStack}.\acall{push}(\avar{namespace\_out})$

              \EndIf

              \State $\avar{namespace} \gets \avar{namespaceStack}.\acall{last}()$
              \State $\abreak$

          \EndIf

      \EndFor

      \If{$\akw{null} = \avar{nextToken}$}

        \State $\acall{error}$

      \EndIf

      \State $\avar{offset} \gets \avar{offset} + \avar{nextToken}.\acall{value}.\acall{length()}$
      \State $\avar{sequence}.\acall{push}(\avar{nextToken})$

  \EndWhile

\EndFunction

\end{algorithmic}

\caption{\label{figure:data:algo_lexer} Algorithme de l'analyseur lexical.}

\end{figure}

\begin{example}[Analyse lexicale de \code{<a x="y"><b /><c>foo</c></a>}]
\label{example:data:lexical_analyze}

Avec la grammaire de la figure~\ref{figure:data:xml}, l'analyse lexicale de la
donnée~:
%
$$\code{<a x="y"><b /><c>foo</c></a>}$$
%
produit la séquence suivante~:
%
\begin{center}
\begin{longtable}{rlllr}
   & espace de noms  & lexème       & valeur     & position \\
0  & \code{default}  & \code{lt}    & \code{<}   & 0 \\
1  & \code{in\_tag}  & \code{name}  & \code{a}   & 1 \\
2  & \code{in\_tag}  & \code{name}  & \code{x}   & 3 \\
3  & \code{in\_tag}  & \code{equal} & \code{=}   & 4 \\
4  & \code{in\_tag}  & \code{value} & \code{"y"} & 5 \\
5  & \code{in\_tag}  & \code{gt}    & \code{>}   & 8 \\
6  & \code{default}  & \code{lt}    & \code{<}   & 9 \\
7  & \code{in\_tag}  & \code{name}  & \code{b}   & 10 \\
8  & \code{in\_tag}  & \code{slash} & \code{/}   & 12 \\
9  & \code{in\_tag}  & \code{gt}    & \code{>}   & 13 \\
10 & \code{default}  & \code{lt}    & \code{<}   & 14 \\
11 & \code{in\_tag}  & \code{name}  & \code{c}   & 15 \\
12 & \code{in\_tag}  & \code{gt}    & \code{>}   & 16 \\
13 & \code{default}  & \code{text}  & \code{foo} & 17 \\
14 & \code{default}  & \code{lt}    & \code{<}   & 20 \\
15 & \code{in\_tag}  & \code{slash} & \code{/}   & 21 \\
16 & \code{in\_tag}  & \code{name}  & \code{c}   & 22 \\
17 & \code{in\_tag}  & \code{gt}    & \code{>}   & 23 \\
18 & \code{default}  & \code{lt}    & \code{<}   & 24 \\
19 & \code{in\_tag}  & \code{slash} & \code{/}   & 25 \\
20 & \code{in\_tag}  & \code{name}  & \code{a}   & 26 \\
21 & \code{in\_tag}  & \code{gt}    & \code{>}   & 27 \\
22 & \code{default}  & \code{EOF}   & \code{}    & 29
\end{longtable}
\end{center}

\end{example}

L'analyseur syntaxique prend la suite en dérivant la séquence par rapport aux
règles de la grammaire. Cela consiste à dépiler les lexèmes de la séquence un
par un et à regarder si nous pouvons déplier les règles.

\begin{example}[Analyse syntaxique de \code{<a x="y"><b /><c>foo</c></a>}]
\label{example:data:syntactic_analyze}

Nous allons illustrer l'analyse syntaxique de la séquence obtenue dans
l'exem\-ple~\ref{example:data:lexical_analyze}.

\begin{enumerate}

\item Le premier lexème est déplié~: \code{lt}. La règle \code{xml} est composée
de une ou plusieurs règles \code{tag}. La règle \code{tag} commence par un
lexème \code{lt}. Il y a une correspondance, le processus continue.

\item Le deuxième lexème est \code{name}. La règle \code{tag} se poursuit avec
le lexème \code{name}, il y a une correspondance. Le lexème \code{name} porte
une unification. Le prochain lexème \code{name} pour cette règle devra avoir
comme valeur \code{a}.

\item Le troisième lexème de la séquence est \code{name}. La règle \code{tag}
poursuit avec un appel à la règle \code{attributes} qui commence avec le lexème
\code{name}. Encore une fois, il y a une correspondance.

\item[4-5.] L'opération est identique pour le quatrième (\code{equal}) et
cinquième lexème (\code{value}).

\item[6.] Le sixième lexème est \code{gt}. La règle \code{attributes} demande
soit d'avoir un nouvel attribut, soit la fin de la règle est atteinte, ce qui
est le cas. Donc le processus revient dans la règle \code{tag}. Il y a une
disjonction~: le premier élément ne peut pas dériver \code{gt} (il attend
\code{slash}), mais le second élément le permet. Il y a une correspondance, le
processus continue.

\item[…] Le lexème suivant dans la séquence est utilisé. Et ainsi de suite,
jusqu'à atteindre la fin de la séquence.

\end{enumerate}

\end{example}

Si nous ne pouvons plus dériver la séquence, nous allons revenir en arrière de
$k$ lexèmes jusqu'à retomber sur un point de choix (une disjonction ou une
répétition). Cette étape s'appelle le \inenglish{backtracking}. Dans notre cas,
$k$ n'est pas fixé, nous disons que nous revenons en arrière de $\star$ lexèmes,
soit d'autant de lexèmes que nécessaire.

La séquence est construite en analysant la donnée textuelle de gauche à droite
(\inenglish{{\strong L}eft to right}) et la séquence est dérivée en utilisant
toujours le lexème le plus à gauche de la séquence (\inenglish{{\strong
L}eftmost derivation}), nous avons donc un analyseur $LL(\star)$.

Une fois que la donnée a été validée par l'analyseur syntaxique, le compilateur
est capable de produire un AST, pour \inenglish{Abstract Syntax Tree}, soit un
arbre de syntaxe abstrait. Les constructions \code{\#node} dans la grammaire
permettent de forcer la création d'un nœud dont les enfants seront des nœuds ou
des lexèmes déclarés avec la syntaxe \code{<token>} (l'autre construction
\code{::token::} n'autorise pas les lexèmes à apparaître dans l'arbre). La
figure~\ref{figure:data:ast} montre l'AST résultant des
exemples~\ref{example:data:lexical_analyze} et
\ref{example:data:syntactic_analyze}.
%
\begin{figure}

\fig{\textwidth}{!}{AST.tex}

\caption{\label{figure:data:ast} Arbre de syntaxe abstrait de la donnée \code{<a x="y"><b
/><c>foo</c></a>}.}

\end{figure}
%
Un AST est une structure récursive. Nous pouvons lui appliquer un {\strong
visiteur}~\acite{design-patterns}. Ce \inenglish{design-pattern} permet à
l'utilisateur d'appliquer des traitements supplémentaires~: des contraintes qui
ne peuvent pas être représentées par la grammaire, comme par exemple une
vérification de typage. \\

Ce compilateur de compilateur $LL(\star)$ nous permet de valider une donnée
textuelle complexe. Ainsi, nous respectons la première caractéristique d'un
domaine réaliste~: la prédicabilité. Les parties suivantes illustrent plusieurs
algorithmes de générations de chaînes de caractères à partir d'une grammaire.

\subsection{Algorithmes de génération de données à partir de grammaires}
\label{subsection:data:algorithms}

Nous décrivons maintenant l'utilisation de grammaires pour la génération de
données textuelles complexes, afin d'assurer la caractéristique de générabilité
des domaines réalistes.

Nous proposons trois algorithmes de génération différents~: aléatoire uniforme,
exhaustive bornée et enfin basée sur la couverture. Le principe de ces
algorithmes est résumé dans la figure~\ref{figure:data:grammar}~:
%
\begin{figure}

\fig{\textwidth}{!}{Grammar_based_generation.tex}

\caption{\label{figure:data:grammar} Principe des algorithmes de génération de
données.}

\end{figure}
%
Ainsi, ils vont générer différentes séquences de lexèmes à partir d'une
grammaire. Ces lexèmes vont être concrétisés pour obtenir une donnée
textuelle. L'algorithme de concrétisation est présenté à la fin de la partie.

Pour générer des séquences de lexèmes, les algorithmes vont explorer les règles
de la grammaire selon différentes contraintes~: la taille de la séquence, la
fréquence d'apparition des lexèmes, la quantité de séquences etc. Ces
contraintes sont extraites d'une étude menée de manière empirique auprès d'une
demi-douzaine d'ingénieurs de tests qualifiés, ajoutés à notre propre
expérience. Certains souhaitaient des données de taille fixe ou bornée,
d'autres insistaient sur la diversité des données, ou encore sur la quantité
avec par exemple de l'exhaustivité.

\subsubsection{Génération aléatoire uniforme}
\label{subsection:data:random_uniform_generation}

Cet algorithme permet de générer des séquences de lexèmes de taille $n$ fixe.
Chaque séquence est générée aléatoirement et avec une distribution uniforme
parmi toutes les séquences possibles de taille $n$. Afin d'assurer cette
uniformité, nous allons nous baser sur les travaux de \acitei{FlajoletZC94}. Les
auteurs proposent une méthode de calcul récursive pour compter le nombre de
sous-structures de taille $n$. Ce dénombrement va nous permettre de calculer des
fonctions de répartition pour guider l'algorithme dans l'exploration des règles
à chaque point de choix rencontré. \\
Cet algorithme fonctionne donc en deux étapes. La première est le dénombrement
et la seconde est la génération à proprement parler.

À chaque construction du langage PP est associée une fonction de dénombrement
$\psi(n, e)$ qui compte le nombre de sous-structures de taille $n$ qu'il est
possible de générer pour la construction grammaticale $e$. Ainsi~:

\begin{align*}
%
\psi(n, e) & =
    \delta_n^1
    &
    \text{si $e$ est un lexème}
    \\
%
\psi(n, e_1 \cdot \dotso \cdot e_k) & =
    \sum_{\gamma \,\in\, \Gamma_k^n}
    \prod_{\alpha \,=\, 1}^k
    \psi(\gamma_\alpha, e_\alpha)
    \\
%
\psi(n, e_1 \,\vert\, \dots \,\vert\, e_k) & =
    \sum_{\alpha \,=\, 1}^k
    \psi(n, e_\alpha)
    \\
%
\psi(n, e^{\{x, y\}}) & =
    \sum_{\alpha \,=\, x}^y
    \sum_{\gamma \,\in\, \Gamma_\alpha^n}
    \prod_{\beta \,=\, 1}^\alpha
    \psi(\gamma_\beta, e)
    &
    \text{avec $0 \leq x \leq y$}
%
\end{align*}

Dans la première formule, $\delta_i^j$ est le symbole de Kronecker égal à 1 si
$i = j$, à 0 sinon. $\Gamma_k^n$ désigne l'ensemble des $k$-uplets d'entiers
naturel dont la somme des éléments est égale à $n$. Pour chaque $k$-uplet
$\gamma$ et chaque $\alpha \in [1; k]$, $\gamma_\alpha$ désigne le
$\alpha$\textsuperscript{ième} élément de $\gamma$.
%
Par exemple~:
%
$$\Gamma_3^2 = \{(2, 0, 0), (1, 1, 0), (1, 0, 1), (0, 2, 0), (0, 1, 1), (0, 0,
2)\}$$
%
et pour le premier $k$-uplet, $\gamma_1 = 2$ et $\gamma_2 = \gamma_3 = 0$.

Pour la concaténation, représentée par l'opérateur $\cdot$, la fonction $\psi$
somme de la distribution de $n$ parmi toutes les sous-structures. Pour la
disjonction, représentée par l'opérateur $\vert$, la fonction $\psi$ somme la
taille des sous-structures de taille $n$. Et enfin, une répétition, représentée
par $\{x, y\}$, est une disjonction de concaténations (par exemple,
$e^{\{2,4\}}$ est équivalent à $e \cdot e \,\vert\, e \cdot e \cdot e \,\vert\,
e \cdot e \cdot e \cdot e$). Quand $y$ est non défini (avec \code{*} et
\code{+}), il est considéré égal à $n$.

\begin{example}[Exploration aléatoire uniforme]
\label{example:data:random_uniform_generation}

Soit la grammaire suivante~:
%
\begin{pre}
f: <a> g() \\
g: ( <b> <c> | <d> | f() )\{1,3\}
\end{pre}
%
L'axiome est \code{f}. Nous voulons compter le nombre de sous-structures
possibles de taille 5. Les résultats sont présentés dans la
figure~\ref{figure:data:random_tabular}.  La première colonne montre les valeurs
possibles de $n$.  La deuxième colonne montre les résultats pour $f(n)$.
Ensuite, nous avons les résultats pour $g(n)$, avec le détail~: pour chaque
branche de la disjonction et pour la répétition avec $r = 1$, 2 et 3. Le symbole
«~-~» représente une donnée dupliquée sur la même ligne.

Nous commençons avec $f(5)$ qui signifie~: le nombre de sous-structures de
taille 5 que peut produire la règle \code{f}, soit le résultat de $\psi(5,
\code{<a>} \cdot \code{g()})$. Cette règle commence par un lexème \code{<a>},
donc le reste de la séquence (donné par la règle \code{g}) devra faire une
taille de 4. Nous calculons alors $g(4)$, soit $\psi(4, \code{( <b> <c> | <d> |
f() )}^{\{1,3\}})$. La règle \code{g} est une répétition $r \in [1; 3]$ d'une
disjonction. Avec $r = 1$, le seul moyen d'avoir une sous-structure de taille 4
et de passer par \code{f}, donc nous devons calculer $f(4)$. Avec $r = 2$, nous
pouvons avoir \code{<b> <c> <b> <c>}, ou \code{<b> <c>} puis $f(2)$, ou
\code{<d>} puis $f(3)$ etc. Tous les résultats sont présents dans la
figure~\ref{figure:data:random_tabular}.

\begin{figure}

\begin{center}
\begin{tabular}{c|cc|cccccccccccc}
$n$ & \code{f:} & $\dots$ & \code{g:} & \code{(} &
  \code{<b> <c>} & \code{|} & \code{<d>} & \code{|} & \code{f()} & \code{)} &
  \multicolumn{3}{c}{\code{\{1, 3\}}} \\
\hline
\hline

& & & & & & & & & & $r = $ & 1 & 2 & 3 \\

\hline

5 & 24 & & 73 & & 0 & & 0 & & - & & (24, & 28, & 21)\\
4 & 8  & & 24 & & 0 & & 0 & & - & & (8, & 10, & 6) \\
3 & 3  & & 8  & & 0 & & 0 & & - & & (3, & 4, & 1) \\
2 & 1  & & 3  & & 1 & & 0 & & - & & (2, & 1, & 0) \\
1 & 0  & & 1  & & 0 & & 1 & & - & & (1, & 0, & 0) \\

\hline

\end{tabular}
\end{center}

\caption{\label{figure:data:random_tabular} Exemple des résultats de la fonction
$\psi$.}

\end{figure}

Maintenant, nous sommes outillés pour générer des chaînes de caractères à partir
de la grammaire. Imaginons que nous sommes sur l'exploration de la règle
\code{g} avec $n = 3$. Nous avons une répétition $r \in [1; 3]$. Nous savons
grâce à la fonction $\psi$ que $g(3) = 8$, c'est~à~dire que \code{g} peut
produire 8 sous-structures de taille 3. Il faut choisir aléatoirement et
uniformément une valeur pour $r$, grâce aux probabilités données par la fonction
$\psi(3, \code{( <b> <c> | <d> | f() )}^r)$. Avec $r = 1$, 3 sous-structures
peuvent être produites, avec $r = 2$, 4 sous-structures peuvent être produites
et avec $r = 3$, 1 sous-structure peut être produite. Ainsi~:

$$
p(r = 1) = \frac{3}{8} \qquad
p(r = 2) = \frac{4}{8} \qquad
p(r = 3) = \frac{1}{8}
$$

Pour appliquer les probabilités, nous choisissons un entier $i \in [1; 8]$
aléatoirement et uniformément. Avec $i = 5$, nous obtenons $r = 2$.
%
%\drawfig{6.5cm}{!}{}{
%
%  \draw[->] (-.1,   0) -- (7, 0) node[anchor=north] {$r$}; \draw[->] (  0, -.1)
%  -- (0, 5) node[anchor=east]  {$n$};
%
%  \draw (1, 0) node[anchor=north] {1} (3, 0) node[anchor=north] {2} (5, 0)
%  node[anchor=north] {3};
%
%  \draw (0, 1) node[anchor=east] {1} (0, 2) node[anchor=east] {2} (0, 3)
%  node[anchor=east] {3} (0, 4) node[anchor=east] {4};
%
%  \draw[thick] (0, 3) -- (2, 3) (2, 4) -- (4, 4) (4, 1) -- (6, 1) (2, 0) -- (2,
%  4) (4, 0) -- (4, 4) (6, 0) -- (6, 1);
%
%  \draw (3, -1) node {$\afrac{\uparrow}{i}$};
%
%}
%
Donc nous répétons la disjonction 2~fois. Rappelons que nous traitons la règle
\code{g} avec une taille de 3, donc 3~lexèmes à répartir sur 2~répétitions. Nous
utilisons la fonction $\Gamma$ pour calculer cette répartition~: $\Gamma_2^3 =
\{(2, 1), (1, 2)\}$ (tous les $k$-uplets contenant un 0 ont été supprimés car
c'est impossible de distribuer 0 lexème dans une répétition). Nous allons
utiliser soit 2~lexèmes lors de la première répétition et 1~lexème pour la
seconde, soit l'inverse. Pour choisir, nous tirons un entier $j \in [1;
2]$ aléatoirement et uniformément pour sélectionner le $k$-uplet. Disons que $j
= 1$, donc nous allons utiliser le $k$-uplet $(2, 1)$.

Pour la première répétition, il y a $n = 2$ lexèmes à distribuer. La disjonction
peut produire 2~sous-structures. Nous allons utiliser une nouvelle fonction de
répartition. La disjonction a trois branches~: la première peut produire
1~sous-structure, la deuxième 0 et la dernière 1 sous-structure.  La probabilité
de parcourir la première branche ou la dernière branche est de $\tfrac{1}{2}$.
Et ainsi de suite.

\end{example}

Cet algorithme est efficace comparé aux autres pour calculer des petites
séquences de taille fixe avec beaucoup de diversités dans les résultats
(puisqu'aléatoire). Toutefois, la complexité de l'étape du dénombrement avec la
fonction $\psi$ est quadratique~: $\m{O}(n^2)$. Et malgré l'utilisation
d'heuristiques inspirées de la programmation dynamique, pour une valeur de $n >
10$, au moins 2~heures de calculs sont nécessaires. Ce problème ne concerne que
la première étape de l'algorithme, car l'étape de génération a une complexité
linéaire $\m{O}(n)$~: la génération d'une séquence est la plus rapide de tous
les algorithmes.

\subsubsection{Génération exhaustive bornée}
\label{subsection:data:bounded_exhaustive_generation}

Cet algorithme permet de générer toutes les séquences de lexèmes dont la taille
est au maximum $n$. C'est une génération exhaustive bornée. Des
expériences~\acite{MarinovK01, SullivanYCKJ04} ont montré que générer énormément
de données de façon exhaustive peut être efficace pour détecter des erreurs car
toutes les données sont testées.

À chaque construction du langage PP est associée une fonction $\beta(n, e)$ qui
va calculer le multi-ensemble contenant des séquences de lexèmes de taille $n$
pour la construction grammaticale $e$. Un multi-ensemble, noté $\amultiset{A}$,
est un ensemble avec des répétitions~: en effet, rien ne nous assure que la
grammaire ne puisse pas produire au moins deux séquences identiques mais par des
dérivations/chemins différents. Dans notre implémentation, cette fonction se
comporte comme un itérateur où chaque pas calcule la séquence de lexèmes
suivante. Pour simplifier l'écriture de la fonction $\beta$, nous considérons
que la grammaire PP est en forme normale de Chomsky~\acite{Chomsky56}. Ainsi~:

\begin{align*}
%
\beta(1, e) & =
    \amultiset{e}
    &
    \text{si $e$ est un lexème}
    \\
%
\beta(n, e) & =
    \amultiset{}
    &
    \text{si $n \neq 1$}
    \\
%
\beta(n, e_1 \,\vert\, e_2) & =
    \beta(n, e_1) \union \beta(n, e_2)
    \\
%
\beta(n, e_1 \cdot e_2) & =
    \Union_{p \,=\, 1}^{n - 1}
    \beta(p, e_1) \cdot \beta(n - p, e_2)
    \\
%
\beta(n, e^{\{x, y\}}) & =
    \Union_{p \,=\, x}^y \beta(n, e^p)
    \\
%
%\beta(n, e^*) & =
%    \Union_{p \,=\, 0}^n \beta(n, e^p)
%    \\
%%
%\beta(n, e^+) & =
%    \beta(n, e \cdot e^*)
%    \\
%
\beta(n, e^0) & =
    \amultiset{}
    \\
%
\beta(n, e^1) & =
    \beta(n, e)
    \\
%
\beta(n, e^p) & =
    \beta(n, e \cdot e^{p - 1})
    &
    \text{si $p \geq 2$}
%
\end{align*}

Les opérateurs $\union$ et $\Union$ correspondent à l'union des multi-ensembles.
Quand $y$ est non défini (avec \code{*} et \code{+}), il est considéré égal à
$n$.

\begin{example}[Exploration exhaustive bornée]
\label{example:data:bounded_exhaustive_generation}

Soit la même grammaire que dans
l'exemple~\ref{example:data:random_uniform_generation}, à savoir~:

\begin{pre}
f: <a> g() \\
g: ( <b> <c> | <d> | f() )\{1,3\}
\end{pre}

Nous allons dérouler un exemple pour $n = 10$. Nous commençons par explorer la
règle \code{f}. Nous produisons \code{<a>}, puis nous explorons la règle
\code{g} qui propose une répétition d'une disjonction.  Nous commençons par la
borne inférieure de la répétition puis la première branche de la disjonction,
soit \code{<b> <c>}. La première séquence est donc~: \code{<a> <b> <c>}. La
séquence suivante revient au dernier point de choix pour prendre le chemin
suivant, à savoir la deuxième branche de la disjonction. La deuxième séquence
est donc~: \code{<a> <d>}. Nous continuons avec le troisième point de choix de
la disjonction qui est la règle \code{f}. Nous reprenons un chemin équivalent~:
\code{<a>} puis \code{g}. Nous explorons à nouveau notre répétition, nous
choisissons la borne inférieure et le premier élément de la disjonction. La
troisième séquence est donc~: \code{<a> <a> <b> <c>}. Les séquences suivantes
sont~:

\begin{enumerate}
%\setcounter{enumi}{3}

\item[\phantom{0000}4.] \code{<a> <a> <d>}

\item[\phantom{0000}5.] \code{<a> <a> <a> <b> <c>}

\item[\phantom{0000}6.] \code{<a> <a> <a> <d>}

\item[\phantom{0000}7.] \code{<a> <a> <a> <a> <b> <c>}

\item[\phantom{000}…] …

\item[12150.] \code{<a> <a> <a> <a> <a> <a> <a> <a> <a> <d>}

\end{enumerate}

\end{example}

Cet algorithme est rapide pour calculer des petites séquences avec une
complexité $\m{O}(n)$ dans le meilleur des cas, et l'exhaustivité est très
efficace pour détecter des erreurs. Toutefois, le nombre de séquences générables
peut être important. En effet, nous travaillons avec un multi-ensemble, soit un
ensemble avec des répétitions car une même séquence peut être produite depuis
plusieurs chemins différents si la grammaire n'est pas déterministe. Ainsi, dans
le pire des cas, l'algorithme est exponentiel, dans le meilleur des cas, quand
la grammaire est déterministe, il est linéaire.

\subsubsection{Génération basée sur la couverture}
\label{subsection:data:coverage_based_generation}

Cet algorithme essaye de réduire l'explosion combinatoire de l'algorithme
précédent. Il va générer des séquences en respectant deux critères de
couvertures sur la grammaire~:
%
\begin{itemize}

\item une règle est dite couverte si et si seulement toutes ses sous-règles ont
été couvertes~;

\item un lexème est dit couvert s'il a été utilisé avec succès dans une
séquence.

\end{itemize}
%
Pour assurer une diversité dans les séquences générées, les points de choix sont
résolus aléatoirement parmi les sous-règles non-couvertes. Une heuristique est
utilisée pour borner les répétitions afin de réduire encore plus l'explosion
combinatoire et garantir la terminaison de l'algorithme~: l'opérateur \code{*}
est déplié 0, 1 ou 2~fois, \code{+} est déplié 1 ou 2~fois, et $\{x, y\}$ est
déplié $x$, $x + 1$, $y - 1$ et $y$~fois. L'aspect aléatoire est représenté par
la fonction $\mathrm{rand}(i, j)$ dans la fonction $\phi$.

À chaque construction du langage PP est associée une fonction $\phi(p, e)$ qui
va calculer la prochaine séquence. Cette fonction prend en argument $p$, qui est
le préfixe de la séquence déjà produite (vide au départ), et $e$ est la
construction grammaticale traitée. Dans notre implémentation, cet algorithme se
comporte également comme un itérateur. Ainsi~:

\begin{align*}
%
\phi(p, e) & =
    [e]
    &
    \text{si $e$ est un lexème}
    \\
%
\phi(p, e_1 \cdot e_2) & =
    \phi(\phi(p, e_1), e_2)
    \\
%
\phi(p, e_1 \vert \dotso \vert e_k) & =
    \phi(p, e_1) \oplus \dotso \oplus \phi(p, e_k)
    \\
%
\phi(p, e^?) & =
    [] \oplus \phi(p, e)
    \\
%
\phi(p, e^*) & =
    [] \oplus \bigoplus_{i = 1}^{\mathrm{rand}(0, 2)}
    \phi(p, \underbrace{e \cdot \dotso \cdot e}_i)
    \\
%
\phi(p, e^+) & =
    \bigoplus_{i = 1}^{\mathrm{rand}(1, 2)}
    \phi(p, \underbrace{e \cdot \dotso \cdot e}_i)
    \\
%
\phi(p, e^{\{x, y\}}) & =
    \bigoplus_{i = x}^y \phi(p, \underbrace{e \cdot \dotso \cdot e}_i)
%
\end{align*}

Une séquence vide est représentée par $[]$. Les opérateurs $\oplus$ et
$\bigoplus$ désignent un choix entre plusieurs appels récursifs de la fonction.

\begin{example}[Exploration basée sur la couverture]
\label{example:data:coverage_based_generation}

Soit la même grammaire que dans les exemples précédents, à savoir~:

\begin{pre}
f: <a> g() \\
g: ( <b> <c> | <d> | f() )\{1,3\}
\end{pre}

Nous déroulons un exemple. Nous commençons par déplier la règle \code{f}. Nous
produisons \code{<a>} avant d'explorer la règle \code{g}. Puis nous choisissons
aléatoirement de répéter 3~fois la disjonction. La première fois, nous
choisissons le lexème \code{<d>}. La seconde fois, nous avons le choix entre
\code{<b> <c>} ou \code{f} (\code{<d>} ayant déjà été couvert, nous ne voulons
pas le choisir). Nous choisissons \code{<b> <c>}. Enfin, à la troisième
répétition, il n'y a plus qu'un seul choix n'ayant pas été couvert dans la
disjonction~: nous déplions \code{f} à nouveau. Nous produisons \code{<a>} et
nous continuons dans \code{g}. Tout a été couvert, nous choisissons alors
aléatoirement une répétition (disons 1~fois), puis \code{<a>} dans la
disjonction. L'unique séquence \code{<a> <d> <b> <c> <a> <d>} couvre toutes les
règles et tous les lexèmes de la grammaire.

\end{example}

Cet algorithme est rapide pour des séquences de taille moyenne ou grande avec
une complexité logarithmique $\m{O}(\mathrm{log}~n)$. En pratique, l'algorithme
de génération aléatoire uniforme est plus rapide pour calculer des séquences
avec $n \leq 10$, mais il est rapidement dépassé par celui-ci au-delà. La
diversité entre les séquences générées est dû au choix aléatoire sur les points
de choix. Il génère peu de données mais il couvre toutes les règles et tous les
lexèmes. Enfin, contrairement aux algorithmes précédents, nous ne pouvons pas
contrôler la taille de la séquence.

\subsubsection{Concrétisation aléatoire isotropique de lexèmes}
\label{subsection:data:isotropic_generation}

Les trois algorithmes génèrent des séquences de lexèmes, mais nous n'avons pas
de données concrètes. Pour cela, nous devons transformer les lexèmes en données
afin de produire un mot.

Nous rappelons que les lexèmes sont exprimés avec des expressions régulières au
format PCRE, qui est un langage comme un autre~! Afin d'être capable de
transformer les lexèmes en données concrètes, nous devons les analyser. C'est
pourquoi nous avons écrit la grammaire du langage PCRE avec le langage PP.
Ainsi, nous analysons une expression régulière avec cette grammaire, le
compilateur de compilateurs produit un AST que nous parcourons pour générer une
donnée valide correspondant à l'expression régulière de départ. Ce processus est
détaillé dans la figure~\ref{figure:data:regex}.
%
\begin{figure}

\fig{11.7cm}{!}{Regex_to_word.tex}

\caption{\label{figure:data:regex} Fonctionnement de la concrétisation.}

\end{figure}
%
L'algorithme de génération est aléatoire isotropique~\acite{Sawyer78}~: c'est à
dire qu'il est aléatoire uniforme mais l'uniformité est locale à un point de
choix, et non pas parmi toutes les sous-structures possibles. C'est une approche
nettement plus naïve qu'avec les algorithmes précédents, mais la phase de
concrétisation ne nécessite pas autant d'attention que la génération des
séquences de lexèmes. Les lexèmes représentent l'unité atomique de nos langages,
leur valeur n'est pas censée avoir d'influence lorsque nous utilisons la donnée
concrétisée pour du test ou d'autres applications. De plus, nous sommes plus
intéressés par la forme de la séquence (comme toutes les séquences de manière
exhaustive ou couvrant toute la grammaire) car elle caractérise véritablement
notre donnée.

\begin{example}[Génération aléatoire isotropique]

Soit l'expression régulière suivante~:
%
$$\code{([ae]+|[x-y]!)\{1,3\}}$$
%
Nous allons parcourir cette expression comme si nous parcourions son AST, et à
chaque point de choix, nous allons faire un tirage aléatoire uniforme pour
continuer notre parcours~:

\noindent
\begin{longtable}{lp{7cm}}

\code{\ingray{([ae]+|[w-z]!)}\{1,3\}} &
    nous tirons le nombre de répétitions $r_1 \in [1; 3]$, disons $r_1 = 2$~; \\

\code{([ae]+|[w-z]!)\ingray{([ae]+|[w-z]!)}} &
    nous traitons la première répétition qui est une disjonction, nous traitons
    la branche $d_1 \in [1; 2]$, disons $d_1 = 1$~; \\

\code{([ae]+)\ingray{([ae]+|[w-z]!)}} &
    nous avons une répétition $r_2 \in [1; +\infty[$, disons $r_2 = 2$~; \\

\code{[ae]\ingray{[ae]([ae]+|[w-z]!)}} &
    nous avons une classe de caractères, c'est équivalent ici à une disjonction
    entre \code{a} et \code{e}, nous choisissons \code{e}~;\\

\code{\ingray{e}[ae]\ingray{([ae]+|[w-z]!)}} &
    nous traitons la seconde répétition de $r_2$ et nous choisissons \code{a}~; \\

\code{\ingray{ea}([ae]+|[w-z]!)} & 
    nous traitons la seconde répétition de $r_1$ qui est une disjonction, nous
    traitons la branche $d_2 \in [1; 2]$, disons $d_2 = 2$~; \\

\code{\ingray{ea}([w-z]\ingray{!})} &
    nous avons une classe de caractères qui est une plage entre \code{w} et
    \code{z}, nous choisissons \code{y}~; \\

\code{eay!} &
    nous finissons avec la concaténation, que nous avons déjà appliquée tout le
    long de cet exemple.

\end{longtable}

\noindent
Chaque tirage a été fait aléatoirement et uniformément, mais localement.

\end{example}

Chaque opérateur non borné, comme \code{*} ou \code{+}, est borné à un entier
arbitraire, par défaut 2. \\

Nous nous permettons une petite parenthèse afin d'être complet dans notre
discours. Si nous souhaitons utiliser les algorithmes vus précédemment pour
concrétiser les lexèmes (exprimés avec le langage PCRE), ceci demanderait un
travail supplémentaire. En effet, il faudrait transformer le langage des PCRE
vers le langage PP, et ainsi, nous nous retrouvons dans la même position qu'au
début de cette partie où nous avons une grammaire et nos algorithmes de
génération. Dans une telle grammaire, les nouveaux lexèmes seraient alors des
littéraux (comme \code{a}, \code{b}, \code{0} et autre symbole «~unitaire~»)
facilement générables avec un algorithme aléatoire isotropique. Pour résumer,
cela reviendrait à écrire un compilateur PCRE vers PP. Ce travail a été commencé
par un étudiant d'une autre école~\acite{Kuhner14} suite à un projet sur la
visualisation graphique d'expressions régulières, réalisé avec notre compilateur
et notre grammaire des PCRE. \\

Nous n'avons vu que très peu de constructions qu'offre la syntaxe PCRE, mais il
est possible d'exprimer des choses bien plus complexes. Nous vous encourageons à
lire le manuel~\acite{Hazel05}, le langage est très riche.

\subsubsection{Domaines réalistes \code{Grammar} et \code{Regex}}

Les quatres algorithmes précédents complètent les caractéristiques d'un domaine
réaliste en assurant la générabilité. Nous pouvons alors ajouter à la
bibliothèque standard le domaine réaliste~:
%
$$\code{grammar($F$, $L$)}$$
%
où $F$ est le chemin vers le fichier PP contenant la grammaire. Par défaut, ce
domaine réaliste utilise la génération basée sur la couverture car elle produit
peu de données différentes, relativement vite et couvrant toute la grammaire.
Bien sûr, il est possible de modifier l'algorithme à utiliser pour la
génération. Dans ce cas, $L$ représentera la taille de la séquence souhaitée.

\begin{example}[Utilisation du domaine réaliste \code{Grammar}]

La précondition du contrat suivant spécifie que l'argument \code{\$payload} de
la fonction \code{handle\-Re\-quest} doit être au format XML et que la fonction
doit retourner un booléen~:

\begin{pre}
/** \\
 * \arequires payload: grammar('Xml.pp'); \\
 * \aensures  \aresult: boolean(); \\
 */ \\
function handleRequest ( \$payload ) \{ … \}
\end{pre}

\end{example}

Toutefois, l'expérience nous a montré que les développeurs utilisent plus
souvent des expressions régulières que des grammaires. En effet, ils utilisent
les PCRE quasi-quotidiennement. C'est pourquoi nous ajoutons à la bibliothèque
standard le domaine réaliste~:
%
$$\code{regex($R$)}$$
%
où $R$ est une expression régulière. Ce domaine réaliste utilise une génération
aléatoire isotropique, ce qui correspond à l'usage qu'en font les développeurs.
S'il y a besoin d'utiliser les autres algorithmes, il sera nécessaire de passer
par une grammaire qui offre également plus de finesse dans les résultats. Ce
domaine réaliste est tellement utilisé que Praspel propose une syntaxe
simplifiée pour l'utiliser encore plus rapidement. Ainsi, une expression
régulière doit être encadrée de délimiteurs, par exemple \code{/}, et peut être
suivie d'options (un caractère active une option, comme \code{i} pour modifier
la sensibilité à la casse). La syntaxe simplifiée de Praspel impose le
délimiteur \code{/}.

\begin{example}[Utilisation du domaine réaliste \code{Regex}]

La précondition du contrat suivant spécifie que l'argument \code{\$ip} est une
IPv4 valide, avec ou sans port~:
%
\begin{pre}
/** \\
 * \arequires ip: regex( \\
 *                   '/^(\(\bslash\)*|\(\bslash\)d\{1,3\}(\(\bslash\).\(\bslash\)d\{1,3\})\{3\})(:\(\bslash\)d+)?$/' \\
 *               ); \\
 */
\end{pre}
%
Cette expression régulière accepte des adresses IP de la forme~: \code{*},
\code{*:80}, \code{127.0.0.1} ou \code{127.0.0.1:80}. Si nous devions l'écrire
avec la syntaxe simplifiée, nous aurions~:
%
\begin{pre}
/** \\
 * \arequires ip: /^(\(\bslash\)*|\(\bslash\)d\{1,3\}(\(\bslash\).\(\bslash\)d\{1,3\})\{3\})(:\(\bslash\)d+)?$/; \\
 */
\end{pre}

\end{example}

La partie suivante s'intéresse à la génération d'objets.
