\section{Génération à partir de grammaire pour les chaînes de caractères}
\label{section:data:strings}

Une grammaire est utilisée pour représenter des données textuelles complexes.  À
l'aide d'un compilateur, nous allons nous assurer qu'une donnée (textuelle) est
conforme à une grammaire. C'est une propriété sur deux d'un domaine réaliste~:
ce qui fait des grammaires de bonnes candidates pour être une base d'un domaine
réaliste.

Nous allons en premier lieu nous concentrer sur la première caractéristique des
domaines réalistes, à savoir la prédicabilité, et présenter un langage simple de
description de grammaire ainsi que son interprétation avec un compilateur de
compilateur dédié. Ensuite, nous allons voir comment exploiter une grammaire
pour générer des données valides, et ainsi assurer la seconde caractéristique
des domaines réalistes, à savoir la générabilité.

\subsection{Langage de description de grammaire}
\label{subsection:data:pp}

Une grammaire est constituée de {\strong lexèmes}, unités atomiques lexicales
d'une langue, et de {\strong règles} exprimant l'enchaînement possible des
lexèmes les uns par rapport aux autres. Le langage \inenglish{PHP Parser},
abrégé PP, est utilisé pour exprimer des grammaires \inenglish{top-down} et
algébriques. La syntaxe est principalement inspirée de YACC~\acite{Johnson75} et
JavaCC avec l'ajout de nouvelles constructions.

La déclaration d'un lexème est de la forme suivante~:

\begin{pre}
%token ns_source:name value -> ns_dest
\end{pre}
%
où \code{name} représente son nom, \code{value} sa valeur exprimée avec une
expression régulière, et \code{ns\_source} et \code{ns\_dest} sont des espaces
de nom optionnels. Les expressions régulières sont écrites en utilisant la
syntaxe standard des PCRE~\acite{Hazel05}, très expressives, largement utilisées
et supportées (par exemple dans PHP, Javascript, Perl, Python, Apache, KDE
etc.). Les espaces de noms servent à représenter des sous-ensembles disjoints de
lexèmes pour la phase d'analyse lexicale (détaillée ci-après). Une déclaration
\code{\%skip} est similaire à une déclaration \code{\%token} excepté qu'elle
représente un lexème à «~sauter~», c'est~à~dire à ne pas retenir pour la suite.
Typiquement les espaces dans une expression arithmétique n'ont pas d'importance,
nous pouvons les sauter.

Si un espace de nom source n'est pas précisé, alors il prendra la valeur
\code{default}, qui est l'espace de nom par défaut. L'espace de nom de
destination peut être de la forme spéciale \code{\_\_shift\_\_ * $j$}, avec $j
\geq 1$, ou simplement \code{\_\_shift\_\_} (équivalent à avoir $j = 1$), pour
revenir $j$ espaces de nom en arrière. En effet, il est parfois possible
d'accéder à un lexème depuis plusieurs espaces de nom différents. Cette forme
spéciale répond à cette problématique. \\

\begin{figure}

\begin{bigpre}
%skip          space    \(\bslash\)s \\
%token         lt       <            -> in_tag \\
%token         text     [^<]* \\
%skip   in_tag:space    \(\bslash\)s \\
%token  in_tag:name     \(\bslash\)w+ \\
%token  in_tag:slash    / \\
%token  in_tag:gt       >            -> default \\
%token  in_tag:equal    = \\
%token  in_tag:value    ".*?(?<!\(\bslash\bslash\))" \\
\\
xml: \\
    tag()+ #root \\
tag: \\
    ::lt:: <name[0]> attributes() \\
    ( \\
      ::slash:: ::gt:: #atomic \\
    | ::gt:: ( tag()+ #composite | <text> #textual )? \\
      ::lt:: ::slash:: ::name[0]:: ::gt:: \\
    ) \\
#attributes: \\
    ( <name> ::equal:: <value> )*
\end{bigpre}

\caption{\label{figure:data:xml} Grammaire simplifiée d'un document XML.}

\end{figure}

La Figure~\ref{figure:data:xml} montre un exemple d'une grammaire simplifiée
d'un document XML~\acite{xml}. Elle commence par la déclaration des lexèmes, en
utilisant des espaces de noms pour identifier si l'analyse se déroule à
l'extérieur ou à l'intérieur d'une balise. La règle \code{xml} décrit un
document XML comme une séquence de balises, chaque balise ayant potentiellement
des attributs et étant atomique (\code{<aTag />}), composite (contenant d'autres
balises), contenant du texte (\code{<aTag>with text</aTag>}) ou étant vide. Un
nom de règle (\code{xml}, \code{tag} ou \code{attribute} dans la
Figure~\ref{figure:data:xml}) est suivi du symbole \code{:}, puis d'une nouvelle
ligne, immédiatement suivie par une {\strong déclaration de règle}, préfixée par
des caractères blancs horizontaux (espaces ou tabulations). Les lexèmes peuvent
être référencés en utilisant deux types de constructions. La construction
\code{::token::} signifie que le lexème ne sera pas conservé à la fin du
processus de compilation (détaillé ci-après), contrairement à la construction
\code{<token>}. La construction \code{rule()} représente un appel à une règle.
Évidemment, nous pouvons avoir des appels récursifs. Les opérations de
répétition sont classiques: \code{\{$x$, $y$\}} pour répéter le motif $x$ à $y$
fois, \code{?} est identique à \code{\{0, 1\}}, \code{+} à \code{\{1, \}},
\code{*} à \code{\{0, \}}. Les disjonctions sont représentées par le symbole
\code{\mvert} et le groupement par \code{(} et \code{)}. La construction
\code{\#node} (parfois utilisé comme nom de règle) est utile pour la fin du
processus de compilation.

Si un lexème est suivi de \code{[$i$]} avec $i \geq 0$, nous avons une
unification. C'est une nouvelle construction. Une unification pour les lexèmes
implique que tous les \code{token[$i$]} avec le même $i$ ont la même valeur
localement à la règle.  Remarquons la présence d'une unification de lexème dans
la Figure~\ref{figure:data:xml}~: \code{name[0]} indique que les balises
d'ouverture et de fermeture doivent avoir le même nom. Ainsi, la donnée
\code{<foo>…</foo>} sera considérée comme valide, alors que \code{<foo>…</bar>}
sera considérée comme invalide. Un autre usage courant est la gestion des
guillemets représenté par le lexème \code{\%token quote '|"}, soit un guillemet simple, soit
un double. Ainsi, \code{"…"} comme \code{'…'} doivent être valides, alors que
\code{"…'} ou \code{'…"} devront être invalides. Pour cela, nous écrirons par
exemple \code{quote[1]} dans une règle.

Nous trouverons la grammaire du langage PP en langage PP dans la
Figure~\ref{figure:appendices:grammar_of_pp} à la
page~\pageref{figure:appendices:grammar_of_pp}.

\subsection{Compilateur de compilateur $LL(\star)$}
\label{subsection:data:compiler-compiler}

Le fonctionnement schématique d'un compilateur est présenté dans la
Figure~\ref{figure:data:compiler}. À partir d'un {\strong mot} (d'une donnée
textuelle), nous allons extraire une {\strong séquence} de lexèmes grâce à
l'analyseur {\strong lexical}. Ensuite, cette séquence sera {\strong dérivée}
grâce à l'analyseur {\strong syntaxique} pour savoir si elle est valide ou non.
%
\begin{figure}

\fig{\textwidth}{!}{Compiler.tex}

\caption{\label{figure:data:compiler} Fonctionnement d'un compilateur~: un mot
est transformé en séquence de lexèmes grâce à une analyse lexicale. Et cette
séquence est validée ou invalidée grâce à une analyse syntaxique.}

\end{figure}

Nous expliquons le fonctionnement de l'analyseur lexical. Il va appliquer, dans
l'ordre de déclaration, tous les lexèmes de l'espace de nom courant sur le début
du mot jusqu'à trouver un lexème valide (reconnaissant le début du mot). Le
début du mot reconnu est supprimé pour être ajouté à la suite de la séquence,
avec des données supplémentaires (espace de nom, numéro de lignes, de colonnes
etc.). L'espace de nom est actualisé et l'analyseur recommence jusqu'à atteindre
la fin du mot. Si aucun lexème ne permet de reconnaître le début du mot, alors
une erreur sera levée.

\begin{example}[Analyse lexicale de \code{<a x="y"><b /><c>foo</c></a>}]
\label{example:data:lexical_analyze}

Avec la grammaire de la Figure~\ref{figure:data:xml}, l'analyse lexicale de la
donnée~:
%
$$\code{<a x="y"><b /><c>foo</c></a>}$$
%
produit la séquence suivante~:
\begin{center}
\begin{tabular}{rlllr}
   & espace de nom  & lexème       & valeur     & position \\
0  & \code{default} & \code{lt}    & \code{<}   & 0 \\
1  & \code{in\_tag} & \code{name}  & \code{a}   & 1 \\
2  & \code{in\_tag} & \code{name}  & \code{x}   & 3 \\
3  & \code{in\_tag} & \code{equal} & \code{=}   & 4 \\
4  & \code{in\_tag} & \code{value} & \code{"y"} & 5 \\
5  & \code{in\_tag} & \code{gt}    & \code{>}   & 8 \\
6  & \code{default} & \code{lt}    & \code{<}   & 9 \\
7  & \code{in\_tag} & \code{name}  & \code{b}   & 10 \\
8  & \code{in\_tag} & \code{slash} & \code{/}   & 12 \\
9  & \code{in\_tag} & \code{gt}    & \code{>}   & 13 \\
10 & \code{default} & \code{lt}    & \code{<}   & 14 \\
11 & \code{in\_tag} & \code{name}  & \code{c}   & 15 \\
12 & \code{in\_tag} & \code{gt}    & \code{>}   & 16 \\
13 & \code{default} & \code{text}  & \code{foo} & 17 \\
14 & \code{default} & \code{lt}    & \code{<}   & 20 \\
15 & \code{in\_tag} & \code{slash} & \code{/}   & 21 \\
16 & \code{in\_tag} & \code{name}  & \code{c}   & 22 \\
17 & \code{in\_tag} & \code{gt}    & \code{>}   & 23 \\
18 & \code{default} & \code{lt}    & \code{<}   & 24 \\
19 & \code{in\_tag} & \code{slash} & \code{/}   & 25 \\
20 & \code{in\_tag} & \code{name}  & \code{a}   & 26 \\
21 & \code{in\_tag} & \code{gt}    & \code{>}   & 27 \\
22 & \code{default} & \code{EOF}   & \code{}    & 29
\end{tabular}
\end{center}

\end{example}

L'analyseur syntaxique prend la suite en dérivant la séquence par rapport aux
règles de la grammaire. Cela consiste à dépiler les lexèmes de la séquence un
par un et de regarder si nous pouvons explorer les règles.

\begin{example}[Analyse syntaxique de \code{<a x="y"><b /><c>foo</c></a>}]
\label{example:data:syntactic_analyze}

Nous allons illustrer l'analyse syntaxique de la séquence obtenue dans
l'Exem\-ple~\ref{example:data:lexical_analyze}.

\begin{enumerate}

\item Nous allons dépiler le premier lexème~: \code{lt}. La règle \code{xml} est
composée de une ou plusieurs règles \code{tag}. La règle \code{tag} commence par
un lexème \code{lt}. Nous avons une correspondance, nous continuons.

\item Le deuxième lexème est \code{name}. La règle \code{tag} se poursuit avec
le lexème \code{name}, nous avons une correspondance. Le lexème \code{name}
porte une unification. Le prochain lexème \code{name} pour cette règle devra
avoir comme valeur \code{a}.

\item Nous continuons avec le troisième lexème de la séquence~: \code{name}. La
règle \code{tag} poursuit avec un appel à la règle \code{attributes} qui
commence avec le lexème \code{name}. Encore une fois, nous avons une
correspondance.

\item[4-5.] Pareil pour le quatrième (\code{equal}) et cinquième lexème
(\code{value}).

\item[6.] Le sixième lexème est \code{gt}. La règle \code{attributes} demande
soit d'avoir un nouvel attribut, soit nous avons atteint la fin de la règle, ce
qui est notre cas. Donc nous revenons dans la règle \code{tag}. Nous arrivons
dans une disjonction~: le premier élément ne peut pas dériver \code{gt} (il
attend \code{slash}), mais le second élément le permet. Nous avons une
correspondance, nous continuons.

\item[…] Nous passons au lexème suivant dans la séquence. Et ainsi de suite,
jusqu'à atteindre la fin de la séquence.

\end{enumerate}

\end{example}

Si nous ne pouvons plus dériver la séquence, nous allons revenir en arrière de
$k$-lexèmes jusqu'à retomber sur un point de choix (une disjonction ou une
répétition). Cette étape s'appelle le \inenglish{backtracking}. Dans notre cas,
$k$ est infixé, nous disons que nous revenons en arrière de $\star$-lexèmes,
soit d'autant de lexèmes que nécessaire.

La séquence est construite en analysant la donnée textuelle de gauche à droite
(\inenglish{{\strong L}eft to right}) et la séquence est dérivée en utilisant
toujours le lexème le plus à gauche de la séquence (\inenglish{{\strong
L}eftmost derivation}), nous avons donc un compilateur $LL(\star)$.

Une fois que la donnée a été validée par l'analyseur syntaxique, le compilateur
est capable de produire un AST, pour \inenglish{Abstract Syntax Tree}, soit un
arbre de syntaxe abstrait. Les constructions \code{\#node} dans la grammaire
permettent de forcer la création d'un nœud dont les enfants seront des nœuds ou
des lexèmes déclarés avec la syntaxe \code{<token>} (l'autre construction,
\code{::token::}, n'autorise pas les lexèmes à apparaître dans l'arbre). La
Figure~\ref{figure:data:ast} montre l'AST résultant des
Exemples~\ref{example:data:lexical_analyze} et
\ref{example:data:syntactic_analyze}.
%
\begin{figure}

\fig{\textwidth}{!}{AST.tex}

\caption{\label{figure:data:ast} Arbre de syntaxe abstrait de la donnée \code{<a x="y"><b
/><c>foo</c></a>}.}

\end{figure}
%
Un AST est une structure récursive. Nous pouvons lui appliquer un {\strong
visiteur}~\acite{design-patterns}. Ce \inenglish{design-pattern} permet à
l'utilisateur d'appliquer des traitements supplémentaires~: des contraintes qui
ne peuvent pas être représenter par la grammaire, comme par exemple une
vérification de typage. \\

Nous parlons de {\strong compilateur de compilateur} car la grammaire est tout
d'abord transformée en compilateur, c'est à dire en un analyseur lexical et un
syntaxique. La grammaire nous évite d'avoir à écrire un compilateur à la main. \\

Ce compilateur de compilateur $LL(\star)$ nous permet de valider une donnée
textuelle complexe. Ainsi, nous respectons la première caractéristique d'un
domaine réaliste~: la prédicabilité. Les sections suivantes illustrent plusieurs
algorithmes de générations à partir d'une grmmaire.

%\subsubsection{Utiliser PP avec le domaine réaliste \code{Grammar}}
%
%Une grammaire et sa technique classique de compilation associée permet d'assurer
%la caractéristique de prédicabilité d'un domaine réaliste, en vérifiant qu'une
%donnée est correctement structurée par rapport à une grammaire…
%
%\begin{pre}
%@requires payload: grammar('Json.pp');
%\end{pre}

\subsection{Algorithmes de génération de données à partir de grammaires}
\label{subsection:data:algorithms}

Nous décrivons maintenant l'utilisation de grammaire pour la génération de
données textuelles complexes, afin d'assurer la caractéristique de générabilité
des domaines réalistes.

Nous proposons trois algorithmes de générations différents~: aléatoire et
uniforme, exhaustive bornée et enfin basée sur la couverture. Le principe de
ces algorithmes est résumé dans la Figure~\ref{figure:data:grammar}.
%
\begin{figure}

\fig{\textwidth}{!}{Grammar_based_generation.tex}

\caption{\label{figure:data:grammar} Principe des algorithmes de générations de
données~: à partir d'une grammaire est extraite une séquence de lexème qui est
ensuite concrétisée vers un mot.}

\end{figure}
%
Ils vont générer différentes séquences de lexèmes à partir d'une grammaire, pour
ensuite les concrétiser vers une donnée textuelle. L'algorithme de
concrétisation est présenté en dernier.

Pour générer des séquences de lexèmes, les algorithmes vont explorer les règles
de la grammaire selon différentes contraintes~: la taille de la séquence, la
fréquence d'apparition des lexèmes, la quantité de séquences etc.

\subsubsection{Génération aléatoire et uniforme}
\label{subsection:data:random_uniform_generation}

Cet algorithme permet de générer des séquences de lexèmes de taille $n$ fixe.
Chaque séquence est générée aléatoirement et avec une distribution uniforme
parmi toutes les séquences possibles de taille $n$. Afin d'assurer cette
uniformité, nous allons nous baser sur les travaux de \acitep{FlajoletZC94}. Les
auteurs proposent une méthode de calcul récursive pour compter le nombre de
sous-structures de taille $n$. Ce dénombrement va nous permettre de calculer des
fonctions de répartition pour guider l'algorithme dans l'exploration des règles
à chaque point de choix rencontré.

À chaque construction du langage PP est associée une fonction de dénombrement
$\psi$ qui compte le nombre de sous-structures de taille $n$ qu'il est possible
de générer. Ainsi~:

\begin{align*}
%
\psi(n, e) & =
    \delta_n^1
    &
    \text{si $e$ est un lexème}
    \\
%
\psi(n, e_1 \cdot \dotso \cdot e_k) & =
    \sum_{\gamma \in \Gamma_k^n}
    \prod_{\alpha = 1}^k
    \psi(\gamma_\alpha, e_\alpha)
    \\
%
\psi(n, e_1 \,\vert\, \dots \,\vert\, e_k) & =
    \sum_{\alpha = 1}^k
    \psi(n, e_\alpha)
    \\
%
\psi(n, e^{\{x, y\}}) & =
    \sum_{\alpha = x}^y
    \sum_{\gamma \in \Gamma_\alpha^n}
    \prod_{\beta = 1}^\alpha
    \psi(\gamma_\beta, e)
    &
    \text{avec $0 \leq x \leq y$}
%
\end{align*}

Dans la première formule, $\delta_i^j$ est le symbole de Kronecker, définie
comme 1 si $i = j$, 0 sinon. $\Gamma_k^n$ désigne l'ensemble des $k$-uplets dont
la somme des éléments est égale à $n$. Pour chaque $k$-uplet $\gamma$ et chaque
$\alpha \in [1; k]$, $\gamma_\alpha$ désigne le $\alpha$\textsuperscript{ième}
élément de $\gamma$.
%
Par exemple~:
%
$$\Gamma_3^2 = \{(2, 0, 0), (1, 1, 0), (1, 0, 1), (0, 2, 0), (0, 1, 1), (0, 0,
2)\}$$
%
et pour le premier $k$-uplet, $\gamma_1 = 2$ et $\gamma_2 = \gamma_3 = 0$.

La concaténation, représentée par l'opérateur $\cdot$, somme la distribution de
$n$ parmi toutes les sous-structures. La disjonction, représentée par
l'opérateur $\vert$, somme la taille des sous-structures de taille $n$. Et
enfin, une répétition, représentée par $\{x, y\}$, est une disjonction de
concaténations (en effet, $e^{\{2,4\}} \Leftrightarrow ee \,\vert\, eee
\,\vert\, eeee$). Quand $y$ est non-défini (avec \code{*} et \code{+}), il est
borné à $n$.

\begin{example}[Exploration aléatoire et uniforme]

Soit la grammaire suivante~:

\begin{pre}
f: \\
    <a> g() \\
g: \\
    ( <b> <c> | <d> | f() )\{1,3\}
\end{pre}

Nous voulons compter le nombre de sous-structures possibles de taille 5. Nous
commençons avec $f(5)$ qui signifie~: le nombre de sous-structures de taille 5
que peut produire la règle \code{f}. Cette règle commence par un lexème
\code{a}, donc le reste de la séquence, donné par la règle \code{g}, devra faire
une taille de 4. Nous calculons alors $g(4)$. La règle \code{g} est une
répétition $r \in [1; 3]$ d'une disjonction. Avec $r = 1$, le seul moyen d'avoir
une sous-structure de taille 4 et de passer par \code{f}, donc nous devons
calculer $f(4)$. Avec $r = 2$, nous pouvons avoir \code{bcbc}, \code{bc} puis
$f(2)$, \code{d} puis $f(3)$ etc. Nous arrivons au tableau suivant (les détails
pour chaque concaténation, disjonction et répétition ne sont pas indiqués)~:

\begin{center}
\begin{tabular}{crr}
  & $f$ & $g$ \\
\hline
\hline
5 & 24  & 73 \\
4 &  8  & 24 \\
3 &  3  &  8 \\
2 &  1  &  3 \\
1 &  0  &  1
\end{tabular}
\end{center}

Maintenant, nous explorons. Imaginons que nous sommes sur l'exploration de la
règle \code{g} avec $n = 3$, pour nous intéresser au calcul de la fonction de
répartition d'une répétition. Nous savons que $g(3) = 8$. Nous tirons un nombre
$i \in [0; 8]$ aléatoirement et uniformément. Nous avons tiré $i = 5$. Notre
fonction $\psi$ nous permet de calculer la fonction de répartition suivante~:
%
\drawfig{6.5cm}{!}{}{

  \draw[->] (-.1,   0) -- (7, 0) node[anchor=north] {$r$};
  \draw[->] (  0, -.1) -- (0, 5) node[anchor=east]  {$n$};

  \draw (1, 0) node[anchor=north] {1}
        (3, 0) node[anchor=north] {2}
        (5, 0) node[anchor=north] {3};

  \draw (0, 1) node[anchor=east] {1}
        (0, 2) node[anchor=east] {2}
        (0, 3) node[anchor=east] {3}
        (0, 4) node[anchor=east] {4};

  \draw[thick] (0, 3) -- (2, 3)
               (2, 4) -- (4, 4)
               (4, 1) -- (6, 1)
               (2, 0) -- (2, 4)
               (4, 0) -- (4, 4)
               (6, 0) -- (6, 1);

  \draw (3, -1) node {$\afrac{\uparrow}{i}$};

}
%
Pour $i = 5$, nous savons qu'il faut au maximum 2 répétitions de notre
disjonction dans \code{g} pour produire 3 lexèmes. Nous devons répartir 3 sur la
première et deuxième répétition~: soit 2 et 1, ou 1 et 2. Ce choix se fait
aléatoirement. Disons que nous répartissons 2 lexèmes pour la première
répétition, et 1 lexème pour la seconde répétition. La première répétition nous
permet de produire \code{bc}, et la seconde nous permet de produire \code{d}.

Autrement dit, si nous avons par exemple une disjonction entre deux branches,
que la somme des sous-structures est 100, que la première branche peut produire
30 sous-structures et que la seconde 70, alors la probabilité d'explorer la
première branche est $\tfrac{3}{10}$ et celle de la seconde branche est
$\tfrac{7}{10}$.

%\begin{align*}
%f(5) =\, & 1 \,.\, g(4) \\
%g(4) =\, & ( 0 + 0 + f(4) )\,+ \\
%         & ( 0 + 0 + f(3) ) \,.\, ( 0 + 1 + f(1) )\,+ \\
%         & ( 1 + 0 + f(2) ) \,.\, ( 1 + 0 + f(2) )\,+ \\
%         & ( 0 + 1 + f(1) ) \,.\, ( 0 + 0 + f(3) )\,+ \\
%         & ( 1 + 0 + f(2) ) \,.\, ( 0 + 1 + f(1) ) \,.\, ( 0 + 1 + f(1) )\,+ \\
%         & ( 0 + 1 + f(1) ) \,.\, ( 1 + 0 + f(2) ) \,.\, ( 0 + 1 + f(1) )\,+ \\
%         & ( 0 + 1 + f(1) ) \,.\, ( 0 + 1 + f(1) ) \,.\, ( 1 + 0 + f(2) ) \\
%f(4) =\, & 1 . g(3) \\
%g(3) =\, & \dots
%\end{align*}

\end{example}

Pour explorer une règle, nous utilisons des poids représentant le nombre de
sous-structures pour chaque sous-règle. Alors, nous choisissons uniformément et
aléatoirement un nombre pour sélectionner la prochaine sous-règle à explorer en
fonction de son poids.


Parler de la programmation récursive.

\subsubsection{Génération exhaustive bornée}
\label{subsection:data:bounded_exhaustive_generation}

\begin{align*}
%
\beta(1, e) & =
    \{\code{sample($e$)}\}
    &
    \text{si $e$ est un lexème}
    \\
%
\beta(n, e) & =
    \{\}
    &
    \text{si $n \neq 1$}
    \\
%
\beta(n, e_1 \vert e_2) & =
    \beta(n, e_1) \union \beta(n, e_2)
    \\
%
\beta(n, e_1 \cdot e_2) & =
    \Union_{p = 1}^{n - 1}
    \beta(p, e_1) \cdot \beta(n - p, e_2)
    \\
%
\beta(n, e^{\{x, y\}}) & =
    \Union_{p = x}^y \beta(n, e_p)
    \\
%
\beta(n, e^*) & =
    \Union_{p = 0}^n \beta(n, e_p)
    \\
%
\beta(n, e^+) & =
    \beta(n, e \cdot e^*)
    \\
%
\beta(n, e^0) & =
    \{\}
    \\
%
\beta(n, e^1) & =
    \beta(n, e)
    \\
%
\beta(n, e^p) & =
    \beta(n, e \cdot e^{p - 1})
    &
    \text{si $p \geq 2$}
%
\end{align*}

\subsubsection{Génération basée sur la couverture}
\label{subsection:data:coverage_based_generation}

\begin{align*}
%
\phi(p, e) & =
    [\code{sample($e$)}]
    &
    \text{si $e$ est un lexème}
    \\
%
\phi(p, e_1 \cdot e_2) & =
    \phi(\phi(p, e_1), e_2)
    \\
%
\phi(p, e_1 \vert \dotso \vert e_k) & =
    \phi(p, e_1) \oplus \dotso \oplus \phi(p, e_k)
    \\
%
\phi(p, e^?) & =
    [] \oplus \phi(p, e)
    \\
%
\phi(p, e^*) & =
    [] \oplus \bigoplus_{i = 1}^\infty
    \phi(p, \underbrace{e \cdot \dotso \cdot e}_i)
    \\
%
\phi(p, e^+) & =
    \bigoplus_{i = 1}^\infty \phi(p, \underbrace{e \cdot \dotso \cdot e}_i)
    \\
%
\phi(p, e^{\{x, y\}}) & =
    \bigoplus_{i = x}^y \phi(p, \underbrace{e \cdot \dotso \cdot e}_i)
%
\end{align*}

\subsubsection{Génération isotropique de lexèmes}
\label{subsection:data:isotropic_generation}
